{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfec46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets  #1 time installation\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# import sys, subprocess\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
    "#!pip install scikit-learn\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86a1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import Javascript\n",
    "from ipywidgets import Widget, Text, Button, VBox, Label\n",
    "from traitlets import Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba395c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (20, 50409)\n"
     ]
    }
   ],
   "source": [
    "corpus_path = Path(r\"C:\\Users\\netsi\\OneDrive\\Desktop\\TU Wien\\NLP\\Topic12\\corpus\\corpus.json\")  \n",
    "\n",
    "with corpus_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "doc_ids   = [doc[\"id\"] for doc in corpus]\n",
    "doc_titles = [doc.get(\"title\", \"\") for doc in corpus]\n",
    "doc_texts = [doc[\"text\"] for doc in corpus]\n",
    "\n",
    "#print(doc_titles)\n",
    "\n",
    "# ---- Build TF-IDF vectorizer & matrix ----\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),   # unigrams + bigrams\n",
    "    max_df=0.9,\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(doc_texts)  # num_docs, num_terms\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c37836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 50409\n",
      "Sample features: ['crime' 'crime absence' 'crime acknowledge' 'crime actually'\n",
      " 'crime aggregations' 'crime analysis' 'crime appeared' 'crime attractors'\n",
      " 'crime baltimore' 'crime best']\n",
      "\n",
      "TF-IDF values for sample features):\n",
      "crime                     0.6714\n",
      "crime absence             0.0043\n",
      "crime acknowledge         0.0043\n",
      "crime actually            0.0043\n",
      "crime aggregations        0.0043\n",
      "crime analysis            0.0043\n",
      "crime appeared            0.0043\n",
      "crime attractors          0.0043\n",
      "crime baltimore           0.0043\n",
      "crime best                0.0043\n",
      "\n",
      "Top 10 TF-IDF terms in Document 0:\n",
      "                   term     tfidf\n",
      "1406              crime  0.671356\n",
      "3568           mobility  0.209402\n",
      "986              cities  0.138602\n",
      "1484             crimes  0.134271\n",
      "2412        forecasting  0.129448\n",
      "3175                 lb  0.125609\n",
      "3756                 nn  0.106501\n",
      "1437  crime forecasting  0.090958\n",
      "863                cell  0.088119\n",
      "4189                poi  0.086627\n",
      "4545             recall  0.080868\n",
      "1016               city  0.079953\n",
      "3357               lstm  0.078795\n",
      "5180            spatial  0.074272\n",
      "1343          conv lstm  0.073633\n",
      "1342               conv  0.066089\n",
      "1060                cms  0.064970\n",
      "3574      mobility data  0.064970\n",
      "884               cells  0.064970\n",
      "5135   sociodemographic  0.064970\n"
     ]
    }
   ],
   "source": [
    "start = 12005\n",
    "stop = start + 10\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "print(\"Sample features:\", feature_names[start:stop])   \n",
    "\n",
    "\n",
    "first_doc_vector = tfidf_matrix[0].toarray()[0]\n",
    "nonzero_idx = first_doc_vector.nonzero()[0]\n",
    "\n",
    "print(\"\\nTF-IDF values for sample features):\")\n",
    "for idx in range(start, stop):\n",
    "    print(f\"{feature_names[idx]:25s} {first_doc_vector[idx]:.4f}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"term\": [feature_names[i] for i in nonzero_idx],\n",
    "    \"tfidf\": [first_doc_vector[i] for i in nonzero_idx]\n",
    "}).sort_values(\"tfidf\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 TF-IDF terms in Document 0:\")\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6003821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require.undef('text_sender');\n",
       "\n",
       "define('text_sender', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "\n",
       "    var TextSenderView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "\n",
       "            const box = document.createElement(\"div\");\n",
       "\n",
       "            const input = document.createElement(\"input\");\n",
       "            input.type = \"text\";\n",
       "            input.placeholder = \"Type something…\";\n",
       "            input.style.padding = \"6px\";\n",
       "            input.style.marginRight = \"8px\";\n",
       "\n",
       "            const button = document.createElement(\"button\");\n",
       "            button.innerHTML = \"Send to Python\";\n",
       "            button.style.padding = \"6px 12px\";\n",
       "\n",
       "            button.onclick = () => {\n",
       "                this.send({text: input.value});\n",
       "            };\n",
       "\n",
       "            box.appendChild(input);\n",
       "            box.appendChild(button);\n",
       "\n",
       "            this.el.appendChild(box);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        TextSenderView : TextSenderView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Javascript(\"\"\"\n",
    "require.undef('text_sender');\n",
    "\n",
    "define('text_sender', [\"@jupyter-widgets/base\"], function(widgets) {\n",
    "\n",
    "    var TextSenderView = widgets.DOMWidgetView.extend({\n",
    "        render: function() {\n",
    "\n",
    "            const box = document.createElement(\"div\");\n",
    "\n",
    "            const input = document.createElement(\"input\");\n",
    "            input.type = \"text\";\n",
    "            input.placeholder = \"Type something…\";\n",
    "            input.style.padding = \"6px\";\n",
    "            input.style.marginRight = \"8px\";\n",
    "\n",
    "            const button = document.createElement(\"button\");\n",
    "            button.innerHTML = \"Send to Python\";\n",
    "            button.style.padding = \"6px 12px\";\n",
    "\n",
    "            button.onclick = () => {\n",
    "                this.send({text: input.value});\n",
    "            };\n",
    "\n",
    "            box.appendChild(input);\n",
    "            box.appendChild(button);\n",
    "\n",
    "            this.el.appendChild(box);\n",
    "        }\n",
    "    });\n",
    "\n",
    "    return {\n",
    "        TextSenderView : TextSenderView\n",
    "    };\n",
    "});\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e8d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tfidf(query: str, k: int = 5):\n",
    "    \n",
    "    # Returns top-k documents.\n",
    "\n",
    "    if not query.strip():\n",
    "        return []\n",
    "\n",
    "    # Vectorize query\n",
    "    q_vec = vectorizer.transform([query])  # shape: (1, num_terms)\n",
    "\n",
    "    # Cosine similarity with all docs\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix)[0]  # shape: (num_docs,)\n",
    "\n",
    "    # Get top-k indices\n",
    "    topk_idx = np.argsort(sims)[::-1][:k]\n",
    "\n",
    "    results = []\n",
    "    for rank, idx in enumerate(topk_idx, start=1):\n",
    "        results.append({\n",
    "            \"rank\": rank,\n",
    "            \"score\": float(sims[idx]),\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": doc_titles[idx],\n",
    "            \"text\": doc_texts[idx]\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a0e917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fea43fa68b4028b043eef24de135de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Enter your question:'), Text(value='', placeholder='Type your question here...'), …"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = Label(\"Enter your question:\")\n",
    "txt = Text(placeholder=\"Type your question here...\")\n",
    "btn = Button(description=\"Send\")\n",
    "\n",
    "def on_click(b):\n",
    "    global query\n",
    "    query = txt.value\n",
    "    \n",
    "\n",
    "btn.on_click(on_click)\n",
    "\n",
    "VBox([label, txt, btn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ec8584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can we detect sarcasm using deep learning?\n"
     ]
    }
   ],
   "source": [
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80cf0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2510.10729v1  (cosine similarity=0.3359)\n",
      "Paper name: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[2] 2510.08770v1  (cosine similarity=0.0078)\n",
      "Paper name: Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "--------------------------------------------------------------------------------\n",
      "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform. This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset 4 000 images our experiments demonstrate the advantages of thermal imaging in inference speed accuracy and model size. We achieve up to 100% accuracy using lightweight mode ...\n",
      "\n",
      "[3] 2510.13137v1  (cosine similarity=0.0078)\n",
      "Paper name: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show results at title level\n",
    "results = retrieve_tfidf(query, k=3)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"[{r['rank']}] {r['id']}  (cosine similarity={r['score']:.4f})\")\n",
    "    print(f\"Paper name: {r[\"title\"]}\")\n",
    "    print(\"-\" * 80)\n",
    "    # You might want just a snippet, not full text:\n",
    "    print(r[\"text\"][:500], \"...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfc061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dwh)",
   "language": "python",
   "name": "dwh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
