{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfec46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets  #1 time installation\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# import sys, subprocess\n",
    "#subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
    "#!pip install scikit-learn\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86a1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import Javascript\n",
    "from ipywidgets import Widget, Text, Button, VBox, Label\n",
    "from traitlets import Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba395c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path().resolve().parent.parent \n",
    "corpus_path = Path(os.path.join(base_path, \"corpus_json\", \"corpus.json\"))\n",
    "\n",
    "with corpus_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "doc_ids   = [doc[\"id\"] for doc in corpus]\n",
    "doc_titles = [doc.get(\"title\", \"\") for doc in corpus]\n",
    "doc_texts = [doc[\"text\"] for doc in corpus]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),   # unigrams + bigrams\n",
    "    max_df=0.9,\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(doc_texts)  # num_docs, num_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c37836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 50406\n",
      "Sample features: ['crime' 'crime absence' 'crime acknowledge' 'crime actually'\n",
      " 'crime aggregations' 'crime analysis' 'crime appeared' 'crime attractors'\n",
      " 'crime baltimore' 'crime best']\n",
      "\n",
      "TF-IDF values for sample features):\n",
      "crime                     0.6713\n",
      "crime absence             0.0043\n",
      "crime acknowledge         0.0043\n",
      "crime actually            0.0043\n",
      "crime aggregations        0.0043\n",
      "crime analysis            0.0043\n",
      "crime appeared            0.0043\n",
      "crime attractors          0.0043\n",
      "crime baltimore           0.0043\n",
      "crime best                0.0043\n",
      "\n",
      "Top 10 TF-IDF terms in Document 0:\n",
      "                   term     tfidf\n",
      "1406              crime  0.671330\n",
      "3568           mobility  0.209394\n",
      "986              cities  0.138597\n",
      "1484             crimes  0.134266\n",
      "2412        forecasting  0.129443\n",
      "3175                 lb  0.125604\n",
      "3756                 nn  0.106497\n",
      "1437  crime forecasting  0.090954\n",
      "863                cell  0.088116\n",
      "4189                poi  0.086623\n"
     ]
    }
   ],
   "source": [
    "start = 12005\n",
    "stop = start + 10\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Number of features:\", len(feature_names))\n",
    "print(\"Sample features:\", feature_names[start:stop])   \n",
    "\n",
    "\n",
    "first_doc_vector = tfidf_matrix[0].toarray()[0]\n",
    "nonzero_idx = first_doc_vector.nonzero()[0]\n",
    "\n",
    "print(\"\\nTF-IDF values for sample features):\")\n",
    "for idx in range(start, stop):\n",
    "    print(f\"{feature_names[idx]:25s} {first_doc_vector[idx]:.4f}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"term\": [feature_names[i] for i in nonzero_idx],\n",
    "    \"tfidf\": [first_doc_vector[i] for i in nonzero_idx]\n",
    "}).sort_values(\"tfidf\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 TF-IDF terms in Document 0:\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e8d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tfidf(query: str, k: int = 5):\n",
    "    \n",
    "    # Returns top-k documents.\n",
    "\n",
    "    if not query.strip():\n",
    "        return []\n",
    "\n",
    "    # Vectorize query\n",
    "    q_vec = vectorizer.transform([query])  # shape: (1, num_terms)\n",
    "\n",
    "    # Cosine similarity with all docs\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix)[0]  # shape: (num_docs,)\n",
    "\n",
    "    # Get top-k indices\n",
    "    topk_idx = np.argsort(sims)[::-1][:k]\n",
    "\n",
    "    results = []\n",
    "    for rank, idx in enumerate(topk_idx, start=1):\n",
    "        results.append({\n",
    "            \"rank\": rank,\n",
    "            \"score\": float(sims[idx]),\n",
    "            \"id\": doc_ids[idx],\n",
    "            \"title\": doc_titles[idx],\n",
    "            \"text\": doc_texts[idx]\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474e03b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Question: How are Transformers different from RNNs?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.05736v1  (cosine similarity=0.0217)\n",
      "Paper title: Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "--------------------------------------------------------------------------------\n",
      "Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes. The identification of γ-rays from the predominant hadronic-background is a key aspect in their ground-based detection using Imaging Atmospheric Cherenkov Telescopes IACTs. While current methods are limited in their ability to exploit correlations in complex data deep learning-based models offer a promising alternative by directly leveraging image-level information. Howeve ...\n",
      "\n",
      "[2] 2510.05163v1  (cosine similarity=0.0099)\n",
      "Paper title: Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches. In the era of pervasive cyber threats and exponential growth in digital services the inadequacy of single-factor authentication has become increasingly evident. Multi-Factor Authentication MFA which combines knowledge-based factors passwords PINs possessionbased factors smart cards tokens and inherence-based factors biometric traits has emerged as a robust defense mechanism. Recent break ...\n",
      "\n",
      "[3] 2510.10729v1  (cosine similarity=0.0099)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "================================================================================\n",
      "Question: What are the advantages and drawbacks of batch normalization compared to layer normalization?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.08662v1  (cosine similarity=0.0319)\n",
      "Paper title: DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "--------------------------------------------------------------------------------\n",
      "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops. With the continuous growth of the global population food security has become a critical challenge in the global agricultural sector. In this context enhancing the efficiency and precision of crop breeding is of paramount importance. Genomic Selection GS an advanced breeding methodology leverages whole-genome information to predict crop phenotypes significantly accelerating the breeding process. However traditional G ...\n",
      "\n",
      "[2] 2510.13137v1  (cosine similarity=0.0227)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[3] 2510.11073v1  (cosine similarity=0.0202)\n",
      "Paper title: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "--------------------------------------------------------------------------------\n",
      "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer. Patient face images provide a convenient mean for evaluating eye diseases while also raising privacy concerns. Here we introduce ROFI a deep learning-based privacy protection framework for ophthal-mology. Using weakly supervised learning and neural identity translation ROFI anonymizes facial features while retaining disease features over 98% accuracy κ 0.90. It achieves 100% diagnostic sensitivity and  ...\n",
      "\n",
      "================================================================================\n",
      "Question: What regularization techniques help reduce overfitting in large language models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.13137v1  (cosine similarity=0.0699)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[2] 2510.12850v1  (cosine similarity=0.0621)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[3] 2510.10729v1  (cosine similarity=0.0292)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "================================================================================\n",
      "Question: Which learning rate schedules are most effective when training deep learning models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.12850v1  (cosine similarity=0.0323)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[2] 2510.11073v1  (cosine similarity=0.0181)\n",
      "Paper title: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "--------------------------------------------------------------------------------\n",
      "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer. Patient face images provide a convenient mean for evaluating eye diseases while also raising privacy concerns. Here we introduce ROFI a deep learning-based privacy protection framework for ophthal-mology. Using weakly supervised learning and neural identity translation ROFI anonymizes facial features while retaining disease features over 98% accuracy κ 0.90. It achieves 100% diagnostic sensitivity and  ...\n",
      "\n",
      "[3] 2510.08662v1  (cosine similarity=0.0178)\n",
      "Paper title: DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "--------------------------------------------------------------------------------\n",
      "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops. With the continuous growth of the global population food security has become a critical challenge in the global agricultural sector. In this context enhancing the efficiency and precision of crop breeding is of paramount importance. Genomic Selection GS an advanced breeding methodology leverages whole-genome information to predict crop phenotypes significantly accelerating the breeding process. However traditional G ...\n",
      "\n",
      "================================================================================\n",
      "Question: What problems might I encounter when fine-tuning models on domain-specific data?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.12850v1  (cosine similarity=0.1161)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[2] 2510.09187v1  (cosine similarity=0.0249)\n",
      "Paper title: Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "[3] 2510.07320v1  (cosine similarity=0.0131)\n",
      "Paper title: Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children. Autism Spectrum Disorder ASD significantly influences the communication abilities learning processes behavior and social interactions of people. Although early intervention and customized educational strategies are critical to improving outcomes there is a pivotal gap in understanding and addressing nuanced behavioral patterns and emotional identification in autistic children prior to s ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I assess image-text alignment in multimodal models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.10729v1  (cosine similarity=0.0828)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[2] 2510.11073v1  (cosine similarity=0.0356)\n",
      "Paper title: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "--------------------------------------------------------------------------------\n",
      "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer. Patient face images provide a convenient mean for evaluating eye diseases while also raising privacy concerns. Here we introduce ROFI a deep learning-based privacy protection framework for ophthal-mology. Using weakly supervised learning and neural identity translation ROFI anonymizes facial features while retaining disease features over 98% accuracy κ 0.90. It achieves 100% diagnostic sensitivity and  ...\n",
      "\n",
      "[3] 2510.12850v1  (cosine similarity=0.0296)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "================================================================================\n",
      "Question: What metrics should I use to evaluate text generation models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.10729v1  (cosine similarity=0.0679)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[2] 2510.12850v1  (cosine similarity=0.0492)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[3] 2510.13137v1  (cosine similarity=0.0238)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can we detect sarcasm using deep learning?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.10729v1  (cosine similarity=0.3360)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[2] 2510.08770v1  (cosine similarity=0.0078)\n",
      "Paper title: Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "--------------------------------------------------------------------------------\n",
      "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform. This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset 4 000 images our experiments demonstrate the advantages of thermal imaging in inference speed accuracy and model size. We achieve up to 100% accuracy using lightweight mode ...\n",
      "\n",
      "[3] 2510.13137v1  (cosine similarity=0.0078)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I detect or measure bias in deep learning models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.10822v1  (cosine similarity=0.1061)\n",
      "Paper title: From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "--------------------------------------------------------------------------------\n",
      "From Detection to Mitigation Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis. Deep learning models have shown promise in improving diagnostic accuracy from chest Xrays but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work we present a comprehensive bias detection and mitigation framework targeting sex age and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN XGBoost  ...\n",
      "\n",
      "[2] 2510.10729v1  (cosine similarity=0.0233)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[3] 2510.08770v1  (cosine similarity=0.0143)\n",
      "Paper title: Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "--------------------------------------------------------------------------------\n",
      "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform. This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset 4 000 images our experiments demonstrate the advantages of thermal imaging in inference speed accuracy and model size. We achieve up to 100% accuracy using lightweight mode ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I reduce hallucinations in large language models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.13137v1  (cosine similarity=0.0851)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[2] 2510.12850v1  (cosine similarity=0.0437)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[3] 2510.10729v1  (cosine similarity=0.0319)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "================================================================================\n",
      "Question: What techniques improve Transformer training speed without losing performance?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.09187v1  (cosine similarity=0.0365)\n",
      "Paper title: Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "[2] 2510.12850v1  (cosine similarity=0.0338)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[3] 2510.11073v1  (cosine similarity=0.0191)\n",
      "Paper title: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "--------------------------------------------------------------------------------\n",
      "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer. Patient face images provide a convenient mean for evaluating eye diseases while also raising privacy concerns. Here we introduce ROFI a deep learning-based privacy protection framework for ophthal-mology. Using weakly supervised learning and neural identity translation ROFI anonymizes facial features while retaining disease features over 98% accuracy κ 0.90. It achieves 100% diagnostic sensitivity and  ...\n",
      "\n",
      "================================================================================\n",
      "Question: Are deep learning methods effective for crime forecasting compared to traditional models?\n",
      "Correct paper: [2509.20913v1] Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2509.20913v1  (cosine similarity=0.3640)\n",
      "Paper title: Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales. To develop a deep learning framework to evaluate if and how incorporating micro-level mobility features alongside historical crime and sociodemo-graphic data enhances predictive performance in crime forecasting at fine-grained spatial and temporal resolutions. We advance the literature on computational methods and crime forecasting by focusing on four U.S. cities i.e. Baltimore Chicago Los Angeles an ...\n",
      "\n",
      "[2] 2510.13050v1  (cosine similarity=0.0268)\n",
      "Paper title: An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting\n",
      "--------------------------------------------------------------------------------\n",
      "An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting. Precipitation nowcasting which predicts rainfall up to a few hours ahead is a critical tool for vulnerable communities in the Global South that are frequently exposed to intense rapidly developing storms. For these regions timely forecasts provide a crucial window to protect lives and livelihoods. Traditional numerical weather prediction NWP methods often suffer from high latencies low spatial and temporal ...\n",
      "\n",
      "[3] 2510.08411v1  (cosine similarity=0.0151)\n",
      "Paper title: Emergent Denoising of SDSS Galaxy Spectra Through Unsupervised Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Emergent Denoising of SDSS Galaxy Spectra Through Unsupervised Deep Learning. Spectroscopy represents the ideal observational method to maximally extract information from galaxies regarding their star formation and chemical enrichment histories. However absorption spectra of galaxies prove rather challenging at high redshift or in low mass galaxies due to the need to spread the photons into a relatively large set of spectral bins. For this reason the data from many state-of-the-art spectroscopic ...\n",
      "\n",
      "================================================================================\n",
      "Question: Should I train separate models for different crime types, or combine them?\n",
      "Correct paper: [2509.20913v1] Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2509.20913v1  (cosine similarity=0.3420)\n",
      "Paper title: Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales. To develop a deep learning framework to evaluate if and how incorporating micro-level mobility features alongside historical crime and sociodemo-graphic data enhances predictive performance in crime forecasting at fine-grained spatial and temporal resolutions. We advance the literature on computational methods and crime forecasting by focusing on four U.S. cities i.e. Baltimore Chicago Los Angeles an ...\n",
      "\n",
      "[2] 2510.13937v1  (cosine similarity=0.0162)\n",
      "Paper title: Rock Classification through Knowledge-Enhanced Deep Learning: A Hybrid Mineral-Based Approach\n",
      "--------------------------------------------------------------------------------\n",
      "Rock Classification through Knowledge-Enhanced Deep Learning A Hybrid Mineral-Based Approach. Automated rock classification from mineral composition presents a significant challenge in geological applications with critical implications for material recycling resource management and industrial processing. While existing methods using One-dimensional Convolutional Neural Network 1D-CNN excel at mineral identification through Raman spectroscopy the crucial step of determining rock types from minera ...\n",
      "\n",
      "[3] 2510.14855v1  (cosine similarity=0.0151)\n",
      "Paper title: A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution\n",
      "--------------------------------------------------------------------------------\n",
      "A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution. Early detection of melanoma has grown to be essential because it significantly improves survival rates but automated analysis of skin lesions still remains challenging. ABCDE which stands for Asymmetry Border irregularity Color variation Diameter and Evolving is a well-known classification method for skin lesions but most deep learning mechanisms treat it as a black box as most of th ...\n",
      "\n",
      "================================================================================\n",
      "Question: Which deep learning approaches work well for gamma/hadron separation?\n",
      "Correct paper: [2510.05736v1] Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.05736v1  (cosine similarity=0.1157)\n",
      "Paper title: Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "--------------------------------------------------------------------------------\n",
      "Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes. The identification of γ-rays from the predominant hadronic-background is a key aspect in their ground-based detection using Imaging Atmospheric Cherenkov Telescopes IACTs. While current methods are limited in their ability to exploit correlations in complex data deep learning-based models offer a promising alternative by directly leveraging image-level information. Howeve ...\n",
      "\n",
      "[2] 2510.08116v1  (cosine similarity=0.0143)\n",
      "Paper title: Random Window Augmentations for Deep Learning Robustness in CT and Liver Tumor Segmentation\n",
      "--------------------------------------------------------------------------------\n",
      "Random Window Augmentations for Deep Learning Robustness in CT and Liver Tumor Segmentation. Contrast-enhanced Computed Tomography CT is important for diagnosis and treatment planning for various medical conditions. Deep learning DL based segmentation models may enable automated medical image analysis for detecting and delineating tumors in CT images thereby reducing clinicians workload. Achieving generalization capabilities in limited data domains such as radiology requires modern DL models to  ...\n",
      "\n",
      "[3] 2510.09187v1  (cosine similarity=0.0111)\n",
      "Paper title: Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "================================================================================\n",
      "Question: What frameworks and optimization strategies were used to train DPCformer?\n",
      "Correct paper: [2510.08662v1] DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.08662v1  (cosine similarity=0.1161)\n",
      "Paper title: DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "--------------------------------------------------------------------------------\n",
      "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops. With the continuous growth of the global population food security has become a critical challenge in the global agricultural sector. In this context enhancing the efficiency and precision of crop breeding is of paramount importance. Genomic Selection GS an advanced breeding methodology leverages whole-genome information to predict crop phenotypes significantly accelerating the breeding process. However traditional G ...\n",
      "\n",
      "[2] 2510.12850v1  (cosine similarity=0.0139)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[3] 2510.05163v1  (cosine similarity=0.0130)\n",
      "Paper title: Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches. In the era of pervasive cyber threats and exponential growth in digital services the inadequacy of single-factor authentication has become increasingly evident. Multi-Factor Authentication MFA which combines knowledge-based factors passwords PINs possessionbased factors smart cards tokens and inherence-based factors biometric traits has emerged as a robust defense mechanism. Recent break ...\n",
      "\n",
      "================================================================================\n",
      "Question: How do modern architectures perform on complex video tasks compared to older methods?\n",
      "Correct paper: [2510.09187v1] Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.09187v1  (cosine similarity=0.0856)\n",
      "Paper title: Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "[2] 2510.13137v1  (cosine similarity=0.0337)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[3] 2510.10822v1  (cosine similarity=0.0190)\n",
      "Paper title: From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "--------------------------------------------------------------------------------\n",
      "From Detection to Mitigation Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis. Deep learning models have shown promise in improving diagnostic accuracy from chest Xrays but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work we present a comprehensive bias detection and mitigation framework targeting sex age and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN XGBoost  ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I train models stably with limited computational resources?\n",
      "Correct paper: [2510.12850v1] Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.13137v1  (cosine similarity=0.0358)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[2] 2510.10822v1  (cosine similarity=0.0204)\n",
      "Paper title: From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "--------------------------------------------------------------------------------\n",
      "From Detection to Mitigation Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis. Deep learning models have shown promise in improving diagnostic accuracy from chest Xrays but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work we present a comprehensive bias detection and mitigation framework targeting sex age and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN XGBoost  ...\n",
      "\n",
      "[3] 2510.07320v1  (cosine similarity=0.0154)\n",
      "Paper title: Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children. Autism Spectrum Disorder ASD significantly influences the communication abilities learning processes behavior and social interactions of people. Although early intervention and customized educational strategies are critical to improving outcomes there is a pivotal gap in understanding and addressing nuanced behavioral patterns and emotional identification in autistic children prior to s ...\n",
      "\n",
      "================================================================================\n",
      "Question: Why is preprocessing important for Ethic-BERT’s performance?\n",
      "Correct paper: [2510.12850v1] Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.12850v1  (cosine similarity=0.1985)\n",
      "Paper title: Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[2] 2510.10729v1  (cosine similarity=0.0816)\n",
      "Paper title: Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[3] 2510.07320v1  (cosine similarity=0.0331)\n",
      "Paper title: Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children. Autism Spectrum Disorder ASD significantly influences the communication abilities learning processes behavior and social interactions of people. Although early intervention and customized educational strategies are critical to improving outcomes there is a pivotal gap in understanding and addressing nuanced behavioral patterns and emotional identification in autistic children prior to s ...\n",
      "\n",
      "================================================================================\n",
      "Question: What are the main strengths of using an LSTM model for real-time sign language translation?\n",
      "Correct paper: [2510.13137v1] Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.13137v1  (cosine similarity=0.3501)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[2] 2510.11073v1  (cosine similarity=0.0468)\n",
      "Paper title: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "--------------------------------------------------------------------------------\n",
      "ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer. Patient face images provide a convenient mean for evaluating eye diseases while also raising privacy concerns. Here we introduce ROFI a deep learning-based privacy protection framework for ophthal-mology. Using weakly supervised learning and neural identity translation ROFI anonymizes facial features while retaining disease features over 98% accuracy κ 0.90. It achieves 100% diagnostic sensitivity and  ...\n",
      "\n",
      "[3] 2509.23158v1  (cosine similarity=0.0360)\n",
      "Paper title: Deep Learning-Based Detection of Cognitive Impairment from Passive Smartphone Sensing with Routine-Aware Augmentation and Demographic Personalization\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning-Based Detection of Cognitive Impairment from Passive Smartphone Sensing with Routine-Aware Augmentation and Demographic Personalization. Early detection of cognitive impairment is critical for timely diagnosis and intervention yet infrequent clinical assessments often lack the sensitivity and temporal resolution to capture subtle cognitive declines in older adults. Passive smartphone sensing has emerged as a promising approach for naturalistic and continuous cognitive monitoring. B ...\n",
      "\n",
      "================================================================================\n",
      "Question: How does model selection affect responsiveness in real-time applications?\n",
      "Correct paper: [2510.13137v1] Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "[1] 2510.13137v1  (cosine similarity=0.1053)\n",
      "Paper title: Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[2] 2510.08770v1  (cosine similarity=0.0425)\n",
      "Paper title: Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "--------------------------------------------------------------------------------\n",
      "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform. This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset 4 000 images our experiments demonstrate the advantages of thermal imaging in inference speed accuracy and model size. We achieve up to 100% accuracy using lightweight mode ...\n",
      "\n",
      "[3] 2510.08662v1  (cosine similarity=0.0326)\n",
      "Paper title: DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "--------------------------------------------------------------------------------\n",
      "DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops. With the continuous growth of the global population food security has become a critical challenge in the global agricultural sector. In this context enhancing the efficiency and precision of crop breeding is of paramount importance. Genomic Selection GS an advanced breeding methodology leverages whole-genome information to predict crop phenotypes significantly accelerating the breeding process. However traditional G ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test all queries\n",
    "query_path = Path(os.path.join(base_path, \"queries_json\", \"queries.json\"))\n",
    "\n",
    "with open(query_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for entry in test_queries:\n",
    "    question = entry[\"question\"]\n",
    "    correct_paper = str(entry[\"correct_paper_id\"]) # id of the correct paper\n",
    "    correct_paper_title = entry[\"correct_paper_title\"]\n",
    "    \n",
    "    retrieved = retrieve_tfidf(query=question, k=3)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Question: {question}\")\n",
    "    if correct_paper != \"None\":\n",
    "        print(f\"Correct paper: [{correct_paper}] {correct_paper_title}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for r in retrieved:\n",
    "        print(f\"[{r['rank']}] {r['id']}  (cosine similarity={r['score']:.4f})\")\n",
    "        print(f\"Paper title: {r['title']}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(r[\"text\"][:500], \"...\")\n",
    "        print()\n",
    "\n",
    "    # store the top-1 and top-3 prediction\n",
    "    top_pred = retrieved[0]['id']\n",
    "    top_3_pred = [r['id'] for r in retrieved]\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"predicted_paper\": top_pred,\n",
    "        \"correct_paper\": correct_paper,\n",
    "        \"is_correct\": correct_paper == top_pred, # correct paper in top-1\n",
    "        \"is_in_top_3\": correct_paper in top_3_pred # correct paper in top-3\n",
    "\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3f1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 9 queries with known correct paper: 88.89%\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_paper",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correct_paper",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_correct",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_in_top_3",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "99509d5f-ee5a-4c45-9aa7-273eb57ad4fd",
       "rows": [
        [
         "11",
         "Are deep learning methods effective for crime forecasting compared to traditional models?",
         "2509.20913v1",
         "2509.20913v1",
         "True",
         "True"
        ],
        [
         "12",
         "Should I train separate models for different crime types, or combine them?",
         "2509.20913v1",
         "2509.20913v1",
         "True",
         "True"
        ],
        [
         "13",
         "Which deep learning approaches work well for gamma/hadron separation?",
         "2510.05736v1",
         "2510.05736v1",
         "True",
         "True"
        ],
        [
         "14",
         "What frameworks and optimization strategies were used to train DPCformer?",
         "2510.08662v1",
         "2510.08662v1",
         "True",
         "True"
        ],
        [
         "15",
         "How do modern architectures perform on complex video tasks compared to older methods?",
         "2510.09187v1",
         "2510.09187v1",
         "True",
         "True"
        ],
        [
         "16",
         "How can I train models stably with limited computational resources?",
         "2510.13137v1",
         "2510.12850v1",
         "False",
         "False"
        ],
        [
         "17",
         "Why is preprocessing important for Ethic-BERT’s performance?",
         "2510.12850v1",
         "2510.12850v1",
         "True",
         "True"
        ],
        [
         "18",
         "What are the main strengths of using an LSTM model for real-time sign language translation?",
         "2510.13137v1",
         "2510.13137v1",
         "True",
         "True"
        ],
        [
         "19",
         "How does model selection affect responsiveness in real-time applications?",
         "2510.13137v1",
         "2510.13137v1",
         "True",
         "True"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_paper</th>\n",
       "      <th>correct_paper</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>is_in_top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Are deep learning methods effective for crime ...</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Should I train separate models for different c...</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Which deep learning approaches work well for g...</td>\n",
       "      <td>2510.05736v1</td>\n",
       "      <td>2510.05736v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What frameworks and optimization strategies we...</td>\n",
       "      <td>2510.08662v1</td>\n",
       "      <td>2510.08662v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do modern architectures perform on complex...</td>\n",
       "      <td>2510.09187v1</td>\n",
       "      <td>2510.09187v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How can I train models stably with limited com...</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why is preprocessing important for Ethic-BERT’...</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are the main strengths of using an LSTM m...</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How does model selection affect responsiveness...</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question predicted_paper  \\\n",
       "11  Are deep learning methods effective for crime ...    2509.20913v1   \n",
       "12  Should I train separate models for different c...    2509.20913v1   \n",
       "13  Which deep learning approaches work well for g...    2510.05736v1   \n",
       "14  What frameworks and optimization strategies we...    2510.08662v1   \n",
       "15  How do modern architectures perform on complex...    2510.09187v1   \n",
       "16  How can I train models stably with limited com...    2510.13137v1   \n",
       "17  Why is preprocessing important for Ethic-BERT’...    2510.12850v1   \n",
       "18  What are the main strengths of using an LSTM m...    2510.13137v1   \n",
       "19  How does model selection affect responsiveness...    2510.13137v1   \n",
       "\n",
       "   correct_paper  is_correct  is_in_top_3  \n",
       "11  2509.20913v1        True         True  \n",
       "12  2509.20913v1        True         True  \n",
       "13  2510.05736v1        True         True  \n",
       "14  2510.08662v1        True         True  \n",
       "15  2510.09187v1        True         True  \n",
       "16  2510.12850v1       False        False  \n",
       "17  2510.12850v1        True         True  \n",
       "18  2510.13137v1        True         True  \n",
       "19  2510.13137v1        True         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# replace \"None\" strings with actual NaN values\n",
    "df_results['correct_paper'] = df_results['correct_paper'].replace(to_replace=\"None\", value=np.nan)\n",
    "\n",
    "# compute accuracy only on rows with a known correct paper\n",
    "accuracy = df_results[df_results['correct_paper'].notna()]['is_correct'].mean()\n",
    "\n",
    "valid_queries = df_results['correct_paper'].notna().sum()\n",
    "\n",
    "print(f\"Accuracy over {valid_queries} queries with known correct paper: {accuracy:.2%}\")\n",
    "\n",
    "df_results[df_results['correct_paper'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cfc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=220, overlap=40):\n",
    "    \n",
    "    #Split text into overlapping chunks.\n",
    "    #chunk_size: target words per chunk\n",
    "    #overlap: how many words to overlap between consecutive chunks\n",
    "    \n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(words)\n",
    "\n",
    "    while start < n:\n",
    "        end = start + chunk_size\n",
    "        chunk_words = words[start:end]\n",
    "        chunk = \" \".join(chunk_words)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        if end >= n:\n",
    "            break\n",
    "\n",
    "        start = end - overlap  \n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebfe7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_texts = []   \n",
    "passage_meta = []   \n",
    "\n",
    "for doc in corpus:\n",
    "    doc_id = doc[\"id\"]\n",
    "    title = doc.get(\"title\", \"\")\n",
    "    text = doc[\"text\"]\n",
    "\n",
    "    chunks = chunk_text(text, chunk_size=220, overlap=40)\n",
    "    start_word = 0\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        end_word = start_word + len(chunk.split())\n",
    "        passage_texts.append(chunk)\n",
    "        passage_meta.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"title\": title,\n",
    "            \"chunk_id\": f\"{doc_id}_chunk_{i}\",\n",
    "            \"start_word\": start_word,\n",
    "            \"end_word\": end_word,\n",
    "        })\n",
    "        start_word = end_word - 40  # keep aligned with overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbf5de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 20\n",
      "Number of passages:  491\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents: {len(corpus)}\")\n",
    "print(f\"Number of passages:  {len(passage_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1c403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=0.9,\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "tfidf_matrix_passages = vectorizer.fit_transform(passage_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf0eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tfidf_chunks(query: str, k: int = 3):\n",
    "    \n",
    "    #Retrieve top-k passages (chunks)\n",
    "    \n",
    "    if not query.strip():\n",
    "        return []\n",
    "\n",
    "    # Vectorize query\n",
    "    q_vec = vectorizer.transform([query])\n",
    "\n",
    "    # Cosine similarity against all passages\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix_passages)[0]\n",
    "\n",
    "    # Top-k indices\n",
    "    topk_idx = np.argsort(sims)[::-1][:k]\n",
    "\n",
    "    results = []\n",
    "    for rank, idx in enumerate(topk_idx, start=1):\n",
    "        meta = passage_meta[idx]\n",
    "        results.append({\n",
    "            \"rank\": rank,\n",
    "            \"score\": float(sims[idx]),\n",
    "            \"text\": passage_texts[idx],\n",
    "            \"doc_id\": meta[\"doc_id\"],\n",
    "            \"title\": meta[\"title\"],\n",
    "            \"chunk_id\": meta[\"chunk_id\"],\n",
    "            \"start_word\": meta[\"start_word\"],\n",
    "            \"end_word\": meta[\"end_word\"],\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8222152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Question: How are Transformers different from RNNs?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0871\n",
      "Paper: 2510.05736v1 — Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "Chunk: 2510.05736v1_chunk_2 (words 360–580)\n",
      "--------------------------------------------------------------------------------\n",
      "Trees BDTs trained on parameterized image features or goodness-of-fit parameters for this task 3 5. Consequently a natural motivation for exploring deep learning-based models stems from the possibility of improving event classification by directly using image-level information. Multiple studies have explored deep learning methods for identifying γ-rays and demonstrated exceptional performance on simulated data 6 10. Most model architectures use convolutional neural networks CNNs for extracting i ...\n",
      "\n",
      "[2] Cosine similarity=0.0667\n",
      "Paper: 2510.05163v1 — Deep Learning-Based Multi-Factor Authentication: A Survey of Biometric and Smart Card Integration Approaches\n",
      "Chunk: 2510.05163v1_chunk_5 (words 900–1120)\n",
      "--------------------------------------------------------------------------------\n",
      "traditional smart cards Trusted Platform Modules TPMs and Secure Enclaves extend these guarantees to general-purpose devices such as smartphones and laptops. These components isolate sensitive data and computations enabling secure biometric enrollment inference and key storage and underpin modern standards such as FIDO2 and Web Authn. In practice effective MFA requires balancing usability cost and risk. A typical modern system may combine a fingerprint scan inherence a smartphone secure enclave  ...\n",
      "\n",
      "[3] Cosine similarity=0.0491\n",
      "Paper: 2510.10822v1 — From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "Chunk: 2510.10822v1_chunk_20 (words 3600–3714)\n",
      "--------------------------------------------------------------------------------\n",
      "subgroup analysis is affected by class imbalance particularly for Black patients. This underrepresentation limits the statistical robustness of bias evaluations and may obscure subtle disparities. Moreover our work focuses only on CNN-based models applied to CXRs. Therefore the generalizability of our findings to other imaging modalities e.g. CT MRI and tasks e.g. segmentation remains to be established. Finally our approach relies on last-layer retraining. While efficient it may be insufficient  ...\n",
      "\n",
      "================================================================================\n",
      "Question: What are the advantages and drawbacks of batch normalization compared to layer normalization?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0971\n",
      "Paper: 2510.12758v1 — PET Head Motion Estimation Using Supervised Deep Learning with Attention\n",
      "Chunk: 2510.12758v1_chunk_9 (words 1620–1840)\n",
      "--------------------------------------------------------------------------------\n",
      "section. To enhance the representation of aggregated information following the cross-attention phase we integrate a Deep Normalization and Fusion DNF module both prior to and after the concatenation process. The DNF module includes a series of convolutional layers batch normalization and Re LU activation to refine the feature integration process. Finally a fully connected multi-layer perceptron MLP block takes the output of the final DNF block to infer the six rigid transformation motion paramet ...\n",
      "\n",
      "[2] Cosine similarity=0.0887\n",
      "Paper: 2510.08662v1 — DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Chunk: 2510.08662v1_chunk_10 (words 1800–2020)\n",
      "--------------------------------------------------------------------------------\n",
      "sequence dimension of the model s input tensor faithfully represents the physical arrangement of SNPs along the chromosome thereby allowing the convolutional and selfattention layers to effectively capture local and long-range spatial dependencies. 5 Uniform Length Padding To facilitate batch processing and conform to the network s fixed input dimensionality the φ S f a1 f a2 0 1 8 1 where denotes concatenation. This representation preserves the positional order of alleles and ensures that disti ...\n",
      "\n",
      "[3] Cosine similarity=0.0785\n",
      "Paper: 2510.08662v1 — DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Chunk: 2510.08662v1_chunk_14 (words 2520–2740)\n",
      "--------------------------------------------------------------------------------\n",
      "1D convolutional layers Conv1D and Re LU activations. The Conv1×1 term denotes a shortcut connection for dimensionality matching and BN is Batch Normalization. This module transforms the raw sequence Xj of each chromosome into a high-level feature map Ej. 2 Cross-Chromosome Information Fusion To model long-range dependencies and potential epistatic effects between different chromosomes the feature maps from all chromosomes Ej Nchr j 1 are concatenated along the sequence dimension to form a unifi ...\n",
      "\n",
      "================================================================================\n",
      "Question: What regularization techniques help reduce overfitting in large language models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1269\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_13 (words 2340–2560)\n",
      "--------------------------------------------------------------------------------\n",
      "b 1 θL b 9 gacc θ t+1 θ t η gacc Nacc 10 9 Adaptive Learning Rate An adaptive learning rate schedule was used reducing the learning rate as training progressed. In Equation 11 η0 is the initial learning rate and t is the training step. Applying an adaptive learning rate in model training dynamically adjusts the step size based on gradient variations improving convergence speed and stability. This technique helps prevent overshooting in high-gradient regions while accelerating learning in flatter ...\n",
      "\n",
      "[2] Cosine similarity=0.0852\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_5 (words 900–1120)\n",
      "--------------------------------------------------------------------------------\n",
      "study on deep learning models for hate speech detection concluding that fine-tuned Ro BERTa models outperformed CNNs and Bi LSTMs in a ternary classification system. Mnassri et al. explored a multi-task learning framework that integrated emotional features with hate speech detection using BERT and m BERT. Their approach improved performance by leveraging shared representations across tasks reducing overfitting and false positives. Saleh et al. investigated the effectiveness of domain-specific wo ...\n",
      "\n",
      "[3] Cosine similarity=0.0744\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_16 (words 2880–3100)\n",
      "--------------------------------------------------------------------------------\n",
      "CNNs offer higher classification accuracy LSTM models strike a better balance between accuracy speed and computational efficiency thus making them more appropriate for real-time sign language recognition systems deployed in practical settings. Moderate using 3D convolution Preprocessing Hand tracking + landmark extraction Strong using LSTM layers Cropping resizing normalization Computation Low lightweight real-time friendly High GPU required Training Data Works with smaller datasets Requires lar ...\n",
      "\n",
      "================================================================================\n",
      "Question: Which learning rate schedules are most effective when training deep learning models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1877\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_13 (words 2340–2560)\n",
      "--------------------------------------------------------------------------------\n",
      "b 1 θL b 9 gacc θ t+1 θ t η gacc Nacc 10 9 Adaptive Learning Rate An adaptive learning rate schedule was used reducing the learning rate as training progressed. In Equation 11 η0 is the initial learning rate and t is the training step. Applying an adaptive learning rate in model training dynamically adjusts the step size based on gradient variations improving convergence speed and stability. This technique helps prevent overshooting in high-gradient regions while accelerating learning in flatter ...\n",
      "\n",
      "[2] Cosine similarity=0.1466\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_12 (words 2160–2380)\n",
      "--------------------------------------------------------------------------------\n",
      "layers where L is the number of transformer layers. Fully fine-tuning in ethical classification tasks helps the model grasp domain-specific ethical nuances leading to more precise and fair decisions. It refines the model s understanding beyond general pre-trained knowledge aligning it with ethical guidelines. This approach minimizes bias enhances reliability and ensures responsible decision-making. L Y L θi L Hj Hj 1 Hi HL θi i 1 2... L 8 j i+1 Gradient Accumulation To address memory constraints ...\n",
      "\n",
      "[3] Cosine similarity=0.1165\n",
      "Paper: 2510.08662v1 — DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Chunk: 2510.08662v1_chunk_3 (words 540–760)\n",
      "--------------------------------------------------------------------------------\n",
      "unprecedented challenges to food conventional GS models often inadequately capture complex non-additive genetic effects which limits their prediction accuracy and robustness. Recently deep learning methods have demonstrated remarkable efficacy in data modeling across diverse scientific domains. Their capacity to automatically learn complex features enables the effective modeling of non-linear relationships between genotype and phenotype rendering them highly suitable for genomic prediction. Geno ...\n",
      "\n",
      "================================================================================\n",
      "Question: What problems might I encounter when fine-tuning models on domain-specific data?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.2416\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_11 (words 1980–2200)\n",
      "--------------------------------------------------------------------------------\n",
      "between terms like Title IX and title ix or US and us preventing misinterpretation. Case-sensitive models also enhance bias detection and policy evaluation by preserving textual integrity. By leveraging this approach we improve the accuracy and reliability of our ethical assessments. 7 3.5 Implementation Details Our implementation is centered around a fine-tuned BERT-based cased model chosen for its strong contextual understanding and adaptability to text classification tasks. In the following w ...\n",
      "\n",
      "[2] Cosine similarity=0.1647\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_8 (words 1440–1660)\n",
      "--------------------------------------------------------------------------------\n",
      "that the utilitarianism subset lacks explicit labels requiring models to infer relative rankings rather than performing direct classification. Additionally the study relied on standard fine-tuning techniques but accuracy could likely improve with more extensive fine-tuning and 4 domain-specific training. These limitations suggest that current models still struggle to integrate ethical reasoning effectively. Pre-trained LLMs have proven highly effective in understanding complex language and conte ...\n",
      "\n",
      "[3] Cosine similarity=0.1376\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_7 (words 1260–1480)\n",
      "--------------------------------------------------------------------------------\n",
      "model with interval Type-2 fuzzy logic for sentiment classification achieving superior performance in handling contextual variations. Similarly Zhang et al. integrated BERT with large LLMs in a hybrid approach improving sentiment intensity prediction and aspect extraction. In the domain of ethical content detection Aziz et al. applied BERT with multi-layered graph convolutional networks to identify sentiment triplets highlighting the model s capability in detecting hate speech and ethically sens ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I assess image-text alignment in multimodal models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0766\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_7 (words 1260–1480)\n",
      "--------------------------------------------------------------------------------\n",
      "detection modules. Each module processes the text independently producing an output feature vector that encapsulates its specialized analysis. 3. Aggregation and Fusion Feature vectors from all modules are aggregated using concatenation and passed through dimensionality reduction e.g. PCA or attention-based fusion to form a composite representation. This vector is processed by the classification engine. 4. Classification Layer A meta-classifier trained on labeled sarcasm datasets takes the fused ...\n",
      "\n",
      "[2] Cosine similarity=0.0654\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_4 (words 720–940)\n",
      "--------------------------------------------------------------------------------\n",
      "space and skin tone detection achieved 95% accuracy in classifying explicit images and videos. Similarly Khandekar et al. focused on NLP techniques for detecting unethical and offensive text leveraging LSTM and Bi LSTM networks which outperformed traditional models with an accuracy of 86.4%. Horne et al. discussed the ethical challenges in automated fake news detection emphasizing algorithmic bias and lack of generalizability. Their analysis of 381 000 news articles revealed the limitations of d ...\n",
      "\n",
      "[3] Cosine similarity=0.0584\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_1 (words 180–400)\n",
      "--------------------------------------------------------------------------------\n",
      "across multidomain datasets. Their work emphasized the combination of spatial and sequential learning for improved accuracy. Razali et al. explored deep contextual embedding techniques highlighting the importance of semantic features and domain knowledge in sarcasm detection. Their model significantly enhanced performance by considering word context at the sentence level. Poria et al. presented a Deep CNN-based architecture for sarcastic tweet classification which captured local text patterns an ...\n",
      "\n",
      "================================================================================\n",
      "Question: What metrics should I use to evaluate text generation models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1305\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_4 (words 720–940)\n",
      "--------------------------------------------------------------------------------\n",
      "space and skin tone detection achieved 95% accuracy in classifying explicit images and videos. Similarly Khandekar et al. focused on NLP techniques for detecting unethical and offensive text leveraging LSTM and Bi LSTM networks which outperformed traditional models with an accuracy of 86.4%. Horne et al. discussed the ethical challenges in automated fake news detection emphasizing algorithmic bias and lack of generalizability. Their analysis of 381 000 news articles revealed the limitations of d ...\n",
      "\n",
      "[2] Cosine similarity=0.0586\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_7 (words 1260–1480)\n",
      "--------------------------------------------------------------------------------\n",
      "detection modules. Each module processes the text independently producing an output feature vector that encapsulates its specialized analysis. 3. Aggregation and Fusion Feature vectors from all modules are aggregated using concatenation and passed through dimensionality reduction e.g. PCA or attention-based fusion to form a composite representation. This vector is processed by the classification engine. 4. Classification Layer A meta-classifier trained on labeled sarcasm datasets takes the fused ...\n",
      "\n",
      "[3] Cosine similarity=0.0520\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_6 (words 1080–1300)\n",
      "--------------------------------------------------------------------------------\n",
      "should be able to understand why a specific piece of content was labeled as sarcastic. Techniques like LIME and SHAP help visualize feature importance and decision rationale. Moreover models should include feedback loops that allow users to flag misclassifications facilitating continual learning and correction. Privacy preservation is essential when scraping social media data for training. Proper anonymization and ethical approval must be obtained before model development. Finally regular auditi ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can we detect sarcasm using deep learning?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.2276\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_2 (words 360–580)\n",
      "--------------------------------------------------------------------------------\n",
      "text using BERT for text embeddings and Dense Net for visual features. Sarcasm detection is vital for enhancing the interpretability of automated systems like sentiment analyzers chatbots and recommendation engines. While humans rely on context tone and expressions machines must infer sarcasm from textual patterns alone. This paper explores a conceptual solution using DCNNs combined with contextual embedding models to understand sarcasm s complex indicators such as irony sentiment contradiction  ...\n",
      "\n",
      "[2] Cosine similarity=0.2136\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Sarcasm is a nuanced and often misinterpreted form of communication especially in text where tone and body language are absent. This paper presents a proposed modular deep learning framework for sarcasm detection leveraging Deep Convolutional Neural Networks DCNNs and contextual models like BERT to analyze linguistic emotional and contextual cues. The system is conceptually designed to integrate sentiment analysis contextual embeddings linguistic feature extraction and emotion detection through  ...\n",
      "\n",
      "[3] Cosine similarity=0.1620\n",
      "Paper: 2510.10729v1 — Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning\n",
      "Chunk: 2510.10729v1_chunk_1 (words 180–400)\n",
      "--------------------------------------------------------------------------------\n",
      "across multidomain datasets. Their work emphasized the combination of spatial and sequential learning for improved accuracy. Razali et al. explored deep contextual embedding techniques highlighting the importance of semantic features and domain knowledge in sarcasm detection. Their model significantly enhanced performance by considering word context at the sentence level. Poria et al. presented a Deep CNN-based architecture for sarcastic tweet classification which captured local text patterns an ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I detect or measure bias in deep learning models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1655\n",
      "Paper: 2510.10822v1 — From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "Chunk: 2510.10822v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "From Detection to Mitigation Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis. Deep learning models have shown promise in improving diagnostic accuracy from chest Xrays but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work we present a comprehensive bias detection and mitigation framework targeting sex age and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN XGBoost  ...\n",
      "\n",
      "[2] Cosine similarity=0.1002\n",
      "Paper: 2510.05736v1 — Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "Chunk: 2510.05736v1_chunk_8 (words 1440–1656)\n",
      "--------------------------------------------------------------------------------\n",
      "50 and the Fast CNN-GNN n 10 model trained via the split-training approach are shown. The applicability of deep learning-based models on IACT observational data remains a key challenge for several reasons. The observational conditions under which such data is taken are far more diverse than those that can be simulated. Additionally, physical uncertainties introduce further discrepancies between simulated and actual observations, challenging the ability of deep learning models to generalize under ...\n",
      "\n",
      "[3] Cosine similarity=0.0881\n",
      "Paper: 2510.08662v1 — DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Chunk: 2510.08662v1_chunk_3 (words 540–760)\n",
      "--------------------------------------------------------------------------------\n",
      "unprecedented challenges to food conventional GS models often inadequately capture complex non-additive genetic effects which limits their prediction accuracy and robustness. Recently deep learning methods have demonstrated remarkable efficacy in data modeling across diverse scientific domains. Their capacity to automatically learn complex features enables the effective modeling of non-linear relationships between genotype and phenotype rendering them highly suitable for genomic prediction. Geno ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I reduce hallucinations in large language models?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0996\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_5 (words 900–1120)\n",
      "--------------------------------------------------------------------------------\n",
      "study on deep learning models for hate speech detection concluding that fine-tuned Ro BERTa models outperformed CNNs and Bi LSTMs in a ternary classification system. Mnassri et al. explored a multi-task learning framework that integrated emotional features with hate speech detection using BERT and m BERT. Their approach improved performance by leveraging shared representations across tasks reducing overfitting and false positives. Saleh et al. investigated the effectiveness of domain-specific wo ...\n",
      "\n",
      "[2] Cosine similarity=0.0910\n",
      "Paper: 2509.23158v1 — Deep Learning-Based Detection of Cognitive Impairment from Passive Smartphone Sensing with Routine-Aware Augmentation and Demographic Personalization\n",
      "Chunk: 2509.23158v1_chunk_5 (words 900–1120)\n",
      "--------------------------------------------------------------------------------\n",
      "to its lightweight architecture and competitive performance in time series modeling. For instance Hong et al. used an LSTM to predict cognitive impairment from daily sleep variables collected via wearables over several months. Umematsu et al. and Yu et al. built LSTMs to forecast future wellbeing of college students based on time series derived from smartphone and wearable sensing. More recent efforts have explored large language models LLMs to infer wellbeing from behavioral time series. While  ...\n",
      "\n",
      "[3] Cosine similarity=0.0885\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_6 (words 1080–1300)\n",
      "--------------------------------------------------------------------------------\n",
      "Wadud et al. examine methods for offensive text classification emphasizing the need for improved multilingual detection. They introduce Deep-BERT a model combining CNN and BERT which enhances accuracy in identifying offensive content across different languages. Also spam detection has been widely explored using traditional ML models and DL approaches. Similarly Maqsood et al. proposed a hybrid approach combining Random Forest Multinomial Naive Bayes and SVM with CNNs observing that SVM outperfor ...\n",
      "\n",
      "================================================================================\n",
      "Question: What techniques improve Transformer training speed without losing performance?\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0735\n",
      "Paper: 2510.11073v1 — ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer\n",
      "Chunk: 2510.11073v1_chunk_33 (words 5940–6160)\n",
      "--------------------------------------------------------------------------------\n",
      "to alter the identity information within the facial image. The process begins with a feature extractor that transforms input image into the deep feature map which consists of a series of convolution layers. The feature map is then flattened into a one-dimensional feature. The private key is a 512-dimensional vector drawn from the Gaussian distribution with unit variance and is pre-pended before the flattened feature. Then the combined features are passed through six Transformer blocks which leve ...\n",
      "\n",
      "[2] Cosine similarity=0.0700\n",
      "Paper: 2510.09187v1 — Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Chunk: 2510.09187v1_chunk_8 (words 1440–1660)\n",
      "--------------------------------------------------------------------------------\n",
      "Sen et al. This work uses a shorter sequence length of 15 frames and introduces random frame sampling as a data augmentation technique. This can improve model generalization by introducing variability during training but it may also fail to capture the full temporal evolution of a shot. The resolution is higher at 180×224 or 224× 224 depending on the specific model. Vision Transformer Hybrid This hybrid model combines a Vision Transformer Vi T with an RNN. A Vi T with a 6-layer Transformer encod ...\n",
      "\n",
      "[3] Cosine similarity=0.0696\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_16 (words 2880–2991)\n",
      "--------------------------------------------------------------------------------\n",
      "of the BERT model implementing gradient accumulation and utilizing advanced tokenization and data augmentation. These techniques allowed the model to effectively combine its pretrained knowledge with task-specific adaptations resulting in superior performance. Despite these successes challenges persist in the Commonsense and Deontology domains especially on the Hard Test Split. Addressing these gaps could involve enriching the training data with more contextually diverse examples incorporating e ...\n",
      "\n",
      "================================================================================\n",
      "Question: Are deep learning methods effective for crime forecasting compared to traditional models?\n",
      "Correct paper: [2509.20913v1] Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Correct passage: we designed a deep learning model using ConvLSTM layers and compared its performance to three baseline models to determine whether the performance improvement of using an advanced computational method compensated for the complexity involved in building it. Lastly, we compared the results from two different LB periods to assess the impact of longer versus shorter time windows on predictive performance. The results led to several key findings. We first demonstrated that ConvLSTM consistently outperformed the three baseline models, particularly in recall, but struggled with precision, especially when using standard metrics. LSTM showed the closest performance in both recall and precision, though it remained slightly below ConvLSTM. LR, while competitive in precision, suffered from low recall, and RF failed to capture meaningful patterns across all data configurations. Therefore, on the one hand, the effort involved in building such an elaborate model was worthwhile, as the other models either struggled with high-dimensional data or, as in the case of LSTM, had to be highly complex to achieve comparable performance. Moreover, it should be noted that ConvLSTM’s high recall values suggest it can predict most instances where at least one crime is likely to occur, minimizing false negatives as intended. However, the low precision results highlight how the extremely unbalanced nature of our forecasting tasks—a byproduct of the fine-grained spatial and temporal scales of the study—makes this approach highly imperfect in terms of reducing false positives\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.2177\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_4 (words 720–940)\n",
      "--------------------------------------------------------------------------------\n",
      "Due to the nonlinear and multidimensional spatiotemporal dynamics that often characterize crime patterns quantitative criminologists along with scholars from other fields 1 have thus recently become increasingly interested in the promising properties of machine and deep learning methods. Compared to more traditional statistical methods these algorithms have in fact often shown to be more effective in capturing complex patterns outplaying less flexible methods in prediction and forecasting tasks. ...\n",
      "\n",
      "[2] Cosine similarity=0.1679\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales. To develop a deep learning framework to evaluate if and how incorporating micro-level mobility features alongside historical crime and sociodemo-graphic data enhances predictive performance in crime forecasting at fine-grained spatial and temporal resolutions. We advance the literature on computational methods and crime forecasting by focusing on four U.S. cities i.e. Baltimore Chicago Los Angeles an ...\n",
      "\n",
      "[3] Cosine similarity=0.1488\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_11 (words 1980–2200)\n",
      "--------------------------------------------------------------------------------\n",
      "have been backed by extensive empirical evidence 24 36 38. Benefiting from the growing integration between traditional data and more innovative sources for a review see these studies usually include mobility features in the form of footfall1 showing that this feature can ameliorate the performance of crime forecasting models when compared to models that only use historical crime features. Persistent crime patterns however are also closely linked to the socioeconomic conditions of neighborhoods.  ...\n",
      "\n",
      "================================================================================\n",
      "Question: Should I train separate models for different crime types, or combine them?\n",
      "Correct paper: [2509.20913v1] Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Correct passage: Concerning the crime types, we found that our model performed best when using all crime types together, rather than separating them into violent and property crimes. This outcome was expected since this configuration results in a more balanced dataset, hence leading to more stable training.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1546\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_45 (words 8100–8320)\n",
      "--------------------------------------------------------------------------------\n",
      "predict most instances where at least one crime is likely to occur minimizing false negatives as intended. However the low precision results highlight how the extremely unbalanced nature of our forecasting tasks a byproduct of the fine-grained spatial and temporal scales of the study makes this approach highly imperfect in terms of reducing false positives. Concerning the crime types we found that our model performed best when using all crime types together rather than separating them into viole ...\n",
      "\n",
      "[2] Cosine similarity=0.0990\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_46 (words 8280–8500)\n",
      "--------------------------------------------------------------------------------\n",
      "that including additional data sources in combination with crime data allows the algorithm to learn more effectively the patterns leading to crime occurrence. Moreover the percentage difference between CS and CMS indicates that mobility data improve performance especially when using shorter LB periods stressing how mobility captures aspects of an urban context that transcend its static socio-economic ecology. These findings not only contribute to those strands of criminological literature con27  ...\n",
      "\n",
      "[3] Cosine similarity=0.0942\n",
      "Paper: 2509.20913v1 — Deep Learning for Crime Forecasting: The Role of Mobility at Fine-grained Spatiotemporal Scales\n",
      "Chunk: 2509.20913v1_chunk_17 (words 3060–3280)\n",
      "--------------------------------------------------------------------------------\n",
      "focused on shipping and trade with a significant African American majority. In contrast Los Angeles is nearly six times larger characterized by a sprawling car-dependent structure and is predominantly home to Latino and Asian communities. A more detailed overview of the four cities can be found in contained four variables the date and time of the crime incident the category of the crime incident and the location of the crime given as latitude and longitude coordinates. Although several crime cat ...\n",
      "\n",
      "================================================================================\n",
      "Question: Which deep learning approaches work well for gamma/hadron separation?\n",
      "Correct paper: [2510.05736v1] Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "Correct passage: The proposed hybrid CNN-GNN models show improvements in classification over parametrized approaches and match the performance of previous deep learning models, thus establishing the technique as a viable approach.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1790\n",
      "Paper: 2510.05736v1 — Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "Chunk: 2510.05736v1_chunk_8 (words 1440–1656)\n",
      "--------------------------------------------------------------------------------\n",
      "50 and the Fast CNN-GNN n 10 model trained via the split-training approach are shown. The applicability of deep learning-based models on IACT observational data remains a key challenge for several reasons. The observational conditions under which such data is taken are far more diverse than those that can be simulated. Additionally, physical uncertainties introduce further discrepancies between simulated and actual observations, challenging the ability of deep learning models to generalize under ...\n",
      "\n",
      "[2] Cosine similarity=0.1431\n",
      "Paper: 2510.05736v1 — Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes\n",
      "Chunk: 2510.05736v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Convolution and Graph-based Deep Learning Approaches for Gamma/Hadron Separation in Imaging Atmospheric Cherenkov Telescopes. The identification of γ-rays from the predominant hadronic-background is a key aspect in their ground-based detection using Imaging Atmospheric Cherenkov Telescopes IACTs. While current methods are limited in their ability to exploit correlations in complex data deep learning-based models offer a promising alternative by directly leveraging image-level information. Howeve ...\n",
      "\n",
      "[3] Cosine similarity=0.0930\n",
      "Paper: 2510.09187v1 — Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Chunk: 2510.09187v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "================================================================================\n",
      "Question: What frameworks and optimization strategies were used to train DPCformer?\n",
      "Correct paper: [2510.08662v1] DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Correct passage: The DPCformer model was implemented using the PyTorch deep learning framework. The Mean Squared Error (MSE) loss function was utilized to quantify the discrepancy between the ground-truth labels and predicted values, and the Adam optimizer was employed for parameter optimization. During training, we integrated a learning rate scheduling strategy (ReduceLROnPlateau) and an early stopping mechanism (EarlyStopping).\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.0787\n",
      "Paper: 2510.08770v1 — Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "Chunk: 2510.08770v1_chunk_10 (words 1800–2020)\n",
      "--------------------------------------------------------------------------------\n",
      "test set and real-time input. The same hardware was used to train the model as was used to collect data A Lenovo Legion Pro 7i with NVIDIA RTX 4080. Data used and real-time testing area were homogeneous across room and liquid types for this comparison For the training strategy the last 5 layers were fine-tuned an RMSprop optimizer was used lr 1e-5 a binary crossentropy loss function was used and early stopping was used with patience 5. A batch size of 8 was used for training and validation while ...\n",
      "\n",
      "[2] Cosine similarity=0.0591\n",
      "Paper: 2510.08770v1 — Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "Chunk: 2510.08770v1_chunk_9 (words 1620–1840)\n",
      "--------------------------------------------------------------------------------\n",
      "yellow juice were used and two rooms were used in data collection Atrium and J234. This resulted in 8 combinations Room x Liquid x Modality. A variety of spill sizes were collected forming a diverse spill dataset. Within these sizes a typical small spill would have a diameter of 2-4 inches with the regions being approximately circular. A typical large spill would have a diameter of up to 12 inches assuming an approximately circular region. Over time these large spill regions deformed as the liqu ...\n",
      "\n",
      "[3] Cosine similarity=0.0530\n",
      "Paper: 2510.08662v1 — DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops\n",
      "Chunk: 2510.08662v1_chunk_17 (words 3060–3280)\n",
      "--------------------------------------------------------------------------------\n",
      "DTT 68.93% PH and 91.41% EW outperforming the second-best methods with improvements of 2.92% against Light GBM 0.74% over Cropformer and 1.10% beyond GEFormer Fig. 3a. Similarly in Beijing DPCformer reaches 93.50% DTT 76.24% PH and 93.01% EW exceeding GEFormer s DTT and PH by 1.48% and 2.40% respectively while surpassing Cropformer s EW by 19.25%. 2 Rice Small-Sample Dataset In resource-limited samples DPCformer demonstrated exceptional capability. For the rice dataset comprising only 530 sample ...\n",
      "\n",
      "================================================================================\n",
      "Question: How do modern architectures perform on complex video tasks compared to older methods?\n",
      "Correct paper: [2510.09187v1] Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Correct passage: Our results strongly suggest that modern architectures, when properly optimized, are superior for complex video tasks. The SOTA model’s success is attributable to the powerful spatial features from EfficientNet and the GRU’s ability to effectively model temporal dependencies, further enhanced by a temporal attention mechanism.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1270\n",
      "Paper: 2510.09187v1 — Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Chunk: 2510.09187v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study. Cricket shot classification from video sequences remains a challenging problem in sports video analysis requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate traditi ...\n",
      "\n",
      "[2] Cosine similarity=0.1256\n",
      "Paper: 2510.09187v1 — Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Chunk: 2510.09187v1_chunk_15 (words 2700–2920)\n",
      "--------------------------------------------------------------------------------\n",
      "and the Performance Gap Total 1 320 284 284 Our results strongly suggest that modern architectures when properly optimized are superior for complex video tasks. The SOTA model s success is attributable to the powerful spatial features from Efficient Net and the GRU s ability to effectively model temporal dependencies further enhanced by a temporal attention mechanism. The performance gap between our results and those reported in prior work is a critical finding. This discrepancy is likely due to ...\n",
      "\n",
      "[3] Cosine similarity=0.1093\n",
      "Paper: 2510.09187v1 — Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study\n",
      "Chunk: 2510.09187v1_chunk_14 (words 2520–2740)\n",
      "--------------------------------------------------------------------------------\n",
      "over traditional approaches. 2 The Performance Gap There is a stark contrast between the accuracies reported in the original Bhat et al. 99.2% and Sen et al. 93% papers and the results from our re-implementation 55.6% and 57.7% respectively. This highlights the critical importance of standardized open-source benchmarking. 3 Architectural Insights The Sensors dilated CNN-GRU approach proves most effective among baseline methods 57.7% while attention-based and vision transformer approaches show su ...\n",
      "\n",
      "================================================================================\n",
      "Question: How can I train models stably with limited computational resources?\n",
      "Correct paper: [2510.12850v1] Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Correct passage: Additionally, the use of gradient accumulation allowed for stable training even with limited resources, optimizing learning efficiency.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1025\n",
      "Paper: 2510.12758v1 — PET Head Motion Estimation Using Supervised Deep Learning with Attention\n",
      "Chunk: 2510.12758v1_chunk_42 (words 7560–7780)\n",
      "--------------------------------------------------------------------------------\n",
      "the model to learn. Additionally Y rotation tends to have a small magnitude. Both reasons make it more difficult for the model to capture Y rotation changes compared with translation changes. Two possible solutions can be used to alleviate this. One is to assign a higher weight to Y rotations in the loss function. The other is to perform data augmentation to increase the variability of Y rotations. We further compared the performance and computational efficiency of two deep learning methods with ...\n",
      "\n",
      "[2] Cosine similarity=0.0969\n",
      "Paper: 2510.10822v1 — From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis\n",
      "Chunk: 2510.10822v1_chunk_19 (words 3420–3640)\n",
      "--------------------------------------------------------------------------------\n",
      "in DL models for CXR diagnosis. By replacing the final classification layer of a CNN with an XGBoost model we demonstrated that it is possible to significantly reduce disparities across sex age and race subgroups while preserving if not improving overall model performance. Our approach generalizes effectively across multiple medical conditions and remains robust in both ID Che Xpert and OOD MIMIC evaluations. Through our experiments we showed that XGBoost outperforms alternative classifier heads ...\n",
      "\n",
      "[3] Cosine similarity=0.0761\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_4 (words 720–940)\n",
      "--------------------------------------------------------------------------------\n",
      "a novel multi-task learning architecture integrating 3D-CNNs and LSTMs to jointly model spatial and temporal features for action recognition. The 3D-CNN extracts spatiotemporal hierarchies from video inputs while the LSTM captures long-range dependencies across frames. A key innovation is their multi-task framework which simultaneously optimizes for action classification and localization improving generalization. The authors demonstrate state-of-the-art performance on benchmark datasets e.g. UCF ...\n",
      "\n",
      "================================================================================\n",
      "Question: Why is preprocessing important for Ethic-BERT’s performance?\n",
      "Correct paper: [2510.12850v1] Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Correct passage: The preprocessing pipeline was another critical factor in achieving these results. By employing advanced tokenization, consistent input formatting through truncation and padding, the pipeline enhanced the quality and diversity of the training data.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.3541\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification. Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT a BERT-based model for ethical content classification across four domains Commonsense Justice Virtue and Deontology. Leveraging the ETHICS dataset our ...\n",
      "\n",
      "[2] Cosine similarity=0.0904\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_6 (words 1080–1300)\n",
      "--------------------------------------------------------------------------------\n",
      "Wadud et al. examine methods for offensive text classification emphasizing the need for improved multilingual detection. They introduce Deep-BERT a model combining CNN and BERT which enhances accuracy in identifying offensive content across different languages. Also spam detection has been widely explored using traditional ML models and DL approaches. Similarly Maqsood et al. proposed a hybrid approach combining Random Forest Multinomial Naive Bayes and SVM with CNNs observing that SVM outperfor ...\n",
      "\n",
      "[3] Cosine similarity=0.0746\n",
      "Paper: 2510.12850v1 — Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification\n",
      "Chunk: 2510.12850v1_chunk_5 (words 900–1120)\n",
      "--------------------------------------------------------------------------------\n",
      "study on deep learning models for hate speech detection concluding that fine-tuned Ro BERTa models outperformed CNNs and Bi LSTMs in a ternary classification system. Mnassri et al. explored a multi-task learning framework that integrated emotional features with hate speech detection using BERT and m BERT. Their approach improved performance by leveraging shared representations across tasks reducing overfitting and false positives. Saleh et al. investigated the effectiveness of domain-specific wo ...\n",
      "\n",
      "================================================================================\n",
      "Question: What are the main strengths of using an LSTM model for real-time sign language translation?\n",
      "Correct paper: [2510.13137v1] Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Correct passage: The LSTM model, which exploits the temporal dependencies within sequential gesture data, achieved an accuracy of 86.7% on our test dataset. It proved particularly effective in recognizing dynamic gestures that require understanding the order and flow of hand movements, a common trait in sign languages. The LSTM model is lightweight, efficient, and capable of delivering smooth real-time predictions even on low-resource devices.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.2781\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_16 (words 2880–3100)\n",
      "--------------------------------------------------------------------------------\n",
      "CNNs offer higher classification accuracy LSTM models strike a better balance between accuracy speed and computational efficiency thus making them more appropriate for real-time sign language recognition systems deployed in practical settings. Moderate using 3D convolution Preprocessing Hand tracking + landmark extraction Strong using LSTM layers Cropping resizing normalization Computation Low lightweight real-time friendly High GPU required Training Data Works with smaller datasets Requires lar ...\n",
      "\n",
      "[2] Cosine similarity=0.1982\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_0 (words 0–220)\n",
      "--------------------------------------------------------------------------------\n",
      "Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN. This study investigates the performance of 3D Convolutional Neural Networks 3D CNNs and Long Short-Term Memory LSTM networks for real-time American Sign Language ASL recognition. Though 3D CNNs are good at spatiotemporal feature extraction from video sequences LSTMs are optimized for modeling temporal dependencies in sequential data. We evaluate both architectures on a dataset containing 1 20 ...\n",
      "\n",
      "[3] Cosine similarity=0.1779\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_2 (words 360–580)\n",
      "--------------------------------------------------------------------------------\n",
      "2024 their work highlights breakthroughs in spatiotemporal modeling and addresses challenges like limited datasets and cross-signer. Sign language is the primary way that people in the Deaf and Hard of Hearing DHH community communicate yet there s still a big gap because automated translation tech isn t widely used. Recent advancements in deep learning have facilitated notable progress in the development of vision-based systems capable of recognizing and transcribing sign language into text. Two ...\n",
      "\n",
      "================================================================================\n",
      "Question: How does model selection affect responsiveness in real-time applications?\n",
      "Correct paper: [2510.13137v1] Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Correct passage: User testing and qualitative observations reinforced these results: the LSTM model demonstrated higher responsiveness and robustness in live video input, making it preferable for interactive applications such as assistive communication tools. Meanwhile, the 3D CNN, although precise in controlled environments, lacked the adaptability and responsiveness required for real-time translation.\n",
      "--------------------------------------------------------------------------------\n",
      "[1] Cosine similarity=0.1277\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_16 (words 2880–3100)\n",
      "--------------------------------------------------------------------------------\n",
      "CNNs offer higher classification accuracy LSTM models strike a better balance between accuracy speed and computational efficiency thus making them more appropriate for real-time sign language recognition systems deployed in practical settings. Moderate using 3D convolution Preprocessing Hand tracking + landmark extraction Strong using LSTM layers Cropping resizing normalization Computation Low lightweight real-time friendly High GPU required Training Data Works with smaller datasets Requires lar ...\n",
      "\n",
      "[2] Cosine similarity=0.1034\n",
      "Paper: 2510.08770v1 — Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform\n",
      "Chunk: 2510.08770v1_chunk_10 (words 1800–2020)\n",
      "--------------------------------------------------------------------------------\n",
      "test set and real-time input. The same hardware was used to train the model as was used to collect data A Lenovo Legion Pro 7i with NVIDIA RTX 4080. Data used and real-time testing area were homogeneous across room and liquid types for this comparison For the training strategy the last 5 layers were fine-tuned an RMSprop optimizer was used lr 1e-5 a binary crossentropy loss function was used and early stopping was used with patience 5. A batch size of 8 was used for training and validation while ...\n",
      "\n",
      "[3] Cosine similarity=0.1034\n",
      "Paper: 2510.13137v1 — Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN\n",
      "Chunk: 2510.13137v1_chunk_15 (words 2700–2920)\n",
      "--------------------------------------------------------------------------------\n",
      "as input e.g. 30 RGB frames of 128×128 pixels preserving both shape and motion directly. 3D CNN Model Input Sequence of 3D hand landmarks Raw video frames e.g. 30×128×128×3 LSTM Explicitly designed for sequential data making it naturally suited for time-dependent gestures. Focus Temporal sequence modelling Spatiotemporal feature extraction F.Y.B. Tech Students Applied Science Engineering Project1 ASEP1 Paper SEM 2 A.Y. 2024-25 Vishwakarma Institute of Technology Pune INDIA. Additionally while th ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test all queries\n",
    "results = []\n",
    "\n",
    "for entry in test_queries:\n",
    "    question = entry[\"question\"]\n",
    "    correct_paper = str(entry[\"correct_paper_id\"])  # id of the correct paper\n",
    "    correct_paper_title = entry[\"correct_paper_title\"]\n",
    "    \n",
    "    retrieved = retrieve_tfidf_chunks(query=question, k=3)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Question: {question}\")\n",
    "    if correct_paper != \"None\":\n",
    "        print(f\"Correct paper: [{correct_paper}] {correct_paper_title}\")\n",
    "        print(f\"Correct passage: {entry['correct_passage']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for r in retrieved:\n",
    "        print(f\"[{r['rank']}] Cosine similarity={r['score']:.4f}\")\n",
    "        print(f\"Paper: {r['doc_id']} — {r['title']}\")\n",
    "        print(f\"Chunk: {r['chunk_id']} (words {r['start_word']}–{r['end_word']})\")\n",
    "        print(\"-\" * 80)\n",
    "        print(r[\"text\"][:500], \"...\")\n",
    "        print()\n",
    "\n",
    "    top_pred = retrieved[0]['doc_id'] # store only the top-1 prediction\n",
    "    top_3_pred = [r['doc_id'] for r in retrieved] # store top-3 predictions\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"predicted_paper\": top_pred,\n",
    "        \"correct_paper\": correct_paper,\n",
    "        \"is_correct\": correct_paper == top_pred, # correct paper in top-1\n",
    "        \"is_in_top_3\": correct_paper in top_3_pred # correct paper in top-3\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c78709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over 9 queries with known correct paper: 77.78%\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_paper",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correct_paper",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_correct",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_in_top_3",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "55ebd7d1-b960-4e0b-b71b-ff6562a9b15f",
       "rows": [
        [
         "11",
         "Are deep learning methods effective for crime forecasting compared to traditional models?",
         "2509.20913v1",
         "2509.20913v1",
         "True",
         "True"
        ],
        [
         "12",
         "Should I train separate models for different crime types, or combine them?",
         "2509.20913v1",
         "2509.20913v1",
         "True",
         "True"
        ],
        [
         "13",
         "Which deep learning approaches work well for gamma/hadron separation?",
         "2510.05736v1",
         "2510.05736v1",
         "True",
         "True"
        ],
        [
         "14",
         "What frameworks and optimization strategies were used to train DPCformer?",
         "2510.08770v1",
         "2510.08662v1",
         "False",
         "True"
        ],
        [
         "15",
         "How do modern architectures perform on complex video tasks compared to older methods?",
         "2510.09187v1",
         "2510.09187v1",
         "True",
         "True"
        ],
        [
         "16",
         "How can I train models stably with limited computational resources?",
         "2510.12758v1",
         "2510.12850v1",
         "False",
         "False"
        ],
        [
         "17",
         "Why is preprocessing important for Ethic-BERT’s performance?",
         "2510.12850v1",
         "2510.12850v1",
         "True",
         "True"
        ],
        [
         "18",
         "What are the main strengths of using an LSTM model for real-time sign language translation?",
         "2510.13137v1",
         "2510.13137v1",
         "True",
         "True"
        ],
        [
         "19",
         "How does model selection affect responsiveness in real-time applications?",
         "2510.13137v1",
         "2510.13137v1",
         "True",
         "True"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_paper</th>\n",
       "      <th>correct_paper</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>is_in_top_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Are deep learning methods effective for crime ...</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Should I train separate models for different c...</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>2509.20913v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Which deep learning approaches work well for g...</td>\n",
       "      <td>2510.05736v1</td>\n",
       "      <td>2510.05736v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What frameworks and optimization strategies we...</td>\n",
       "      <td>2510.08770v1</td>\n",
       "      <td>2510.08662v1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How do modern architectures perform on complex...</td>\n",
       "      <td>2510.09187v1</td>\n",
       "      <td>2510.09187v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How can I train models stably with limited com...</td>\n",
       "      <td>2510.12758v1</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why is preprocessing important for Ethic-BERT’...</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>2510.12850v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are the main strengths of using an LSTM m...</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How does model selection affect responsiveness...</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>2510.13137v1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question predicted_paper  \\\n",
       "11  Are deep learning methods effective for crime ...    2509.20913v1   \n",
       "12  Should I train separate models for different c...    2509.20913v1   \n",
       "13  Which deep learning approaches work well for g...    2510.05736v1   \n",
       "14  What frameworks and optimization strategies we...    2510.08770v1   \n",
       "15  How do modern architectures perform on complex...    2510.09187v1   \n",
       "16  How can I train models stably with limited com...    2510.12758v1   \n",
       "17  Why is preprocessing important for Ethic-BERT’...    2510.12850v1   \n",
       "18  What are the main strengths of using an LSTM m...    2510.13137v1   \n",
       "19  How does model selection affect responsiveness...    2510.13137v1   \n",
       "\n",
       "   correct_paper  is_correct  is_in_top_3  \n",
       "11  2509.20913v1        True         True  \n",
       "12  2509.20913v1        True         True  \n",
       "13  2510.05736v1        True         True  \n",
       "14  2510.08662v1       False         True  \n",
       "15  2510.09187v1        True         True  \n",
       "16  2510.12850v1       False        False  \n",
       "17  2510.12850v1        True         True  \n",
       "18  2510.13137v1        True         True  \n",
       "19  2510.13137v1        True         True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# replace \"None\" strings with actual NaN values\n",
    "df_results['correct_paper'] = df_results['correct_paper'].replace(to_replace=\"None\", value=np.nan)\n",
    "\n",
    "# compute accuracy only on rows with a known correct paper\n",
    "accuracy = df_results[df_results['correct_paper'].notna()]['is_correct'].mean()\n",
    "\n",
    "valid_queries = df_results['correct_paper'].notna().sum()\n",
    "\n",
    "print(f\"Accuracy over {valid_queries} queries with known correct paper: {accuracy:.2%}\")\n",
    "\n",
    "df_results[df_results['correct_paper'].notna()]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
