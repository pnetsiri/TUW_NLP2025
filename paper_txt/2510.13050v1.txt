Precipitation nowcasting, which predicts rainfall up to a few hours ahead, is a critical tool for vulnerable communities in the Global South that are frequently exposed to intense, rapidly developing storms. For these regions, timely forecasts provide a crucial window to protect lives and livelihoods. Traditional numerical weather prediction (NWP) methods often suffer from high latencies, low spatial and temporal resolutions, and significant gaps in accuracy across the world. Recent progress in machine learning-based nowcasting methods, commonly used in the Global North, cannot be extended to the Global South due to extremely sparse radar coverage. Here, we present Global Met Net, an operationally ready global machine learning nowcasting model. It primarily leverages the Global Precipitation Mission’s (GPM) CORRA dataset and geostationary satellite data, along with global NWP data, to predict precipitation for the next 12 hours. The model operates at a high resolution of approximately 0.05◦(∼5km) spatially and 15 minutes temporally. Global Met Net significantly outperforms industry-standard hourly forecasts and achieves a significantly higher skill, making the forecasts useful in a much larger area of the world than previously available. Our model demonstrates better skill in data-sparse regions than even the best high-resolution NWP models achieve in the US. Validated using ground radar and satellite data, it shows significant improvements across key metrics like the critical success index and fractions skill score for all precipitation rates and lead times. Crucially, our model operates under real-time conditions and generates forecasts in under a minute, making it readily deployable for diverse applications. It is already deployed for millions of users on Google Search. This work represents a key step in reducing global disparities in forecast quality and integrating sparse, high-resolution satellite observations into weather forecasting. Nowcasting, the ability to forecast detailed local weather conditions from the present up to a few hours ahead, is crucial for a wide array of applications. From individuals planning their daily activities, to farmers deciding whether to apply fertilizer, to meteorologists issuing timely warnings for severe weather events, accurate and timely nowcasts are essential. Inaccurate precipitation forecasts can hinder disaster preparedness and response efforts, potentially leading to greater loss of life and property. In fact, the WMO estimates that, over the past 50 years, 22% of deaths and 57% of economic losses caused by natural disasters were the result of “extreme precipitation” events . However, nowcasting, particularly precipitation nowcasting, presents significant challenges, especially in tropical regions. In general, weather forecasting systems benefit greatly from availability of raw observations. Doppler weather radars serve as the foundational instrumentation for the monitoring and forecasting of precipitation. Their operational availability typically determines the precision and spatial resolution Corresponding author(s): shreyaa@google.com © 2025 Google. All rights reserved An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting of meteorological forecasts within any given region. However, coverage of ground-based weather radars is highly uneven across the globe. While dense radar networks exist over North America, Europe and parts of East Asia, there is a severe lack of radar coverage in developing regions, oceans and largely uninhabited areas. This further exacerbates the gaps in accuracy of precipitation forecasts between the Global North and the Global South (see Figure 3). Traditional Numerical Weather Prediction (NWP) methods play a significant, albeit evolving, role in precipitation nowcasting. They serve as a cornerstone for understanding atmospheric dynamics and provide valuable context for shorter-term predictions. However, they also have limitations when applied to the rapid timescales of nowcasting. Running NWP models can be computationally expensive and time consuming, limiting their ability to produce frequent, low-latency updates needed for effective nowcasting (Sun et al., 2014). For example, the High-Resolution Rapid Refresh (HRRR) model, produced by National Oceanic and Atmospheric Administration (NOAA), first collects and processes large amounts of observational data that feeds into their data assimilation system which runs on high-performance computing systems. The initial conditions are then fed to the forecasting system also running on supercomputers to produce the forecasts. This entire process takes about an hour and is limited to the CONUS region. Besides being more actionable in the near future, sub-hourly nowcasts are needed to capture the fine-scale details of convective precipitation which can develop and dissipate in under 30 minutes. AI models promise lower latency, which could support forecasters in capturing these events in a way that is both accurate and timely. While NWP methods have improved in spatial and temporal resolutions over the past few years, achieving a global forecast at a 0.05◦× 0.05◦spatial resolution and 15-minute temporal resolution, with sub-hourly latency, remains a significant challenge for current global NWP systems. The high-resolution forecast (HRES) from the European Centre for Medium-Range Weather Forecasts (ECMWF), while providing global coverage at a 9km resolution, is a medium-range model with a latency of several hours, making it unsuitable for the immediate, sub-hourly updates required for nowcasting. Similarly, HRRR is a 3km spatial resolution model but available within the US only. Additionally, NWPs continue to suffer from the problem of unequal skill in different parts of the world. The application of machine learning to medium-range weather forecasting has seen significant progress, with models like Graph Cast (Lam et al., 2023), Gen Cast (Price et al., 2025), Neural GCM (Kochkov et al., 2024), Pangu-Weather (Bi et al., 2023) and Fuxi (Chen et al., 2023) for medium- range forecasting demonstrating promising results. This growing body of work, however, has not addressed the issue of accuracy gaps in different regions globally. Furthermore, the spatial and temporal resolutions of these models remain similar to their NWP counterparts, as these AI-based systems are built for an entirely different purpose than nowcasting. Radar-based nowcasting methods using machine learning are able to overcome limitations of the traditional methods and showing considerable improvements in accuracy (Espeholt et al., 2022; Piran et al., 2024; Ravuri et al., 2021). Although extremely effective in radar-rich parts of the world, they are inapplicable to most of the rest of the world due to radar-sparsity. Satellite-based methods offer a potential solution, and some work has been done towards this, leveraging techniques such as optical flow are beginning to be adopted in data sparse regions, but have known limitations (World Meteorological Organization, 2023). Rain AI (Pablos-Sarabia et al., 2023) offers a method using EUMETSAT data as input and training against the OPERA network; however, it is unclear whether that approach generalizes to regions without radar. Lebedev et al. (2019) propose a similar satellite-based approach training against the radars in Russia but mention the problem of overfitting to regions with radar and potentially risking coverage of other areas. This work presents a precipitation nowcasting model, Global Met Net, that is globally available but specifically designed to be highly performant in data sparse regions of the world. It bridges the accuracy gaps we see in the current state-of-the-art nowcasting models in most of the world where populations live (see Figure 1). Extending our prior work on Met Net for regional nowcasting Figure 1 | Critical Success Index (CSI) at a 1° resolution for the HRES and Global Met Net model at 1 hour lead time for 1.0 mm/hr of precipitation. (Espeholt et al., 2022), this is a satellite observations based machine learning model with high spatial and temporal resolution that incorporates elements to make it easily operational. Since ground radar is not available globally, our model leverages a global mesh of geostationary satellites as input, and to the best of our knowledge is the first system to use the Global Precipitation Mission’s Combined Radar-Radiometer Precipitation algorithm dataset as a training target. The CORRA dataset combines data from a space-based dual-frequency precipitation radar with a microwave radiometer to create highly accurate estimates of rainfall. It provides near-global coverage and serves as a unique proxy for ground truth. By leveraging this combination of observational data sources, our model provides nowcasts at a 15-minute resolution for the next 12 hours. We evaluate our model against ground weather radar where available, calibrated and quality controlled rain gauges and the CORRA dataset where none of the other ground observations are available. Our model outperforms industry-standard hourly forecasts globally, demonstrating its effectiveness in both data-rich and data-sparse regions. We also show that an optimized HRES forecast, post-processed using our own ML model, is a stronger baseline than the raw HRES forecast itself. Our work is especially critical in the tropics, where the lack of ground radar and other weather infrastructure limits the accuracy of the best-known current nowcasting methods. forecasts, HRRR in the US, and HRES globally. All results have been computed using the Weather Bench- X framework. We compute metrics over various regions of the world because the varying climatologies can significantly impact the numbers. We also show results for varying rates of precipitation from the category of light rain to heavy precipitation. The results highlight substantial enhancements in predicting precipitation events across various lead times and geographical areas. It is important to note that the results here take operational latencies into account. For example, while HRES produces a nowcast for a 1-hour lead time, due to the operational latency, the forecast only becomes available after its valid time has already passed. Hence, in the best-case scenario only the 7 hour lead time forecast of HRES is available as a 1 hour nowcast from any given initialization point (see Figure 14 in the supplement to help demonstrate). The Global Met Net model architecture has been designed to be flexible in the set of training datasets and we show results here for three different versions of our model with the only difference being the input datasets for training. These model variations share the same model architecture but are trained independently allowing each one to optimize model parameters based on their respective inputs. The first model, called Global Met Net Nowcasting contains geostationary datasets and HRES NWP analysis and forecasts only as input. To contrast this, we train a second model that includes high quality ground radar observations, called Global Met Net Nowcasting (with radar input). Both of these models are trained with the following targets as separate output heads: the GPM CORRA dataset, ground radars from the US, Europe and Japan, and the GPM IMERG dataset (more in Table 1 later). A baseline model, called Global Met Net Post-processed HRES, is trained such that it takes only NWP data as input and trained to optimize the GPM CORRA dataset as target only. This baseline model helps calibrate HRES against GPM CORRA dataset and makes for a much stronger baseline than the deterministic forecasts from HRES. The primary goal of this baseline model is to show the importance of additional inputs other than NWP along with the strength of our model architecture. We evaluate our forecasts against quality controlled ground radar datasets, which are considered the gold standard for precipitation measurements, and the GPM CORRA dataset to provide uniform global coverage. For all the following results, our test dataset spans one full year from June 2023 to May 2024. As a spaceborne satellite, the GPM CORRA dataset is not considered as high quality as ground radar (Speirs et al., 2017), primarily because the GPM radar cannot see the precipitation all the way to the surface, and that it does not provide consistent global snapshots, with a revisit rate of 2.5 days; however, it makes for a uniform dataset to evaluate against globally, providing consistent coverage even over oceans, complex terrains or where radar is unavailable. Note here that this dataset only captures sparse measurements and therefore a large enough validation dataset is required to be able to get less noisy evaluation against all possible precipitation rates. Figure 2 | Critical Success Index (CSI) globally and for several regions (Brazil, India, Africa, and the USA), using the GPM CORRA dataset as ground truth at precipitation rates of 0.2 mm/hr (drizzle), 2.4 mm/hr (light rain), 7.0 mm/hr (heavy), and 25.0 mm/hr (very heavy). Figure 2 shows results for our key metric, Critical Success Index (CSI). We see that globally and regionally, for all lead times and precipitation rates, Global Met Net continues to perform better than both the baselines HRES and post-processed HRES. At 0.2 mm/hr globally, Met Net shows a performance improvement of ∼0.18 CSI points over HRES for the first forecasting hour and narrows the gap between the performance of post-processed HRES at about 12 hours. Even for higher precipitation rates of 25.0 mm/hr, Met Net performs much better where HRES is largely unable to predict these extreme events whereas post-processed HRES at least performs better than HRES. At that higher rate of precipitation, there is some visible noise in evaluation due to lack of sufficient observation data at these rates over any given region. Regionally, we see that the performance of HRES in the US is much higher than that over other regions, demonstrating the challenges with predicting chaotic precipitation in the tropics. Notably, the Global Met Net model trained with radar as an additional input, performs better only over regions where radar is included such as the USA. We do not see any influence of ground radar inputs in other places that do not have this data provided as an input to the model. Figure 3 | Forecasting Accuracy Gap: Critical Success Index (CSI) of Global Met Net vs. HRES in the Global South and Global North (top), and Tropics and Mid-Latitudes (bottom), validated against the GPM CORRA dataset at rates of 0.2, 1.0, 2.4, 7.0, and 25.0 mm/hr. Global North includes areas covering USA, Canada, Europe, Japan, and Australia. Global South includes regions covering India, South-east Asia, Middle-east, Africa, Brazil, Mexico, Central America and South America (a) CSI for a precipitation rate of 1.0 mm/hr. (b) CSI for a precipitation rate of 2.4 mm/hr. Figure 4 | Comparison of Critical Success Index (CSI) for HRES and Global Met Net nowcasts at different lead times (3, 6, 9, and 12 hours) for light (1.0 mm/hr) and moderate (2.4 mm/hr) precipitation. Figure 3 shows forecasting accuracy gap between the Global South and Global North and also between the tropics and the mid-latitudes. In Figure 4, we plot the CSI scores for various regions on a map for better context in the improvements we see globally between HRES and Global Met Net. Remarkably, Global Met Net elevates the forecast skill in the Tropics and Global South (blue line) to a level that is comparable to, and for most lead times and precipitation rates exceeds the skill of the industry-standard HRES model in the data-rich Mid-latitudes and the Global North (green line). At 2.4 mm/hr of precipitation, Global Met Net is able to close this forecasting accuracy gap. Overall, this doesn’t just reduce the accuracy gap; it effectively eliminates the gap for certain conditions, representing a pivotal step toward global forecast equity. Figure 5 | Critical Success Index (CSI) for Global Met Net models vs. NWP baselines in the US (vs. MRMS), Europe (vs. Opera), and Japan (vs. JMA) at precipitation rates of 0.2, 2.4, 7.0, and 25.0 mm/hr. Next, in Figure 5, we present results evaluated against ground radar based precipitation estimates over the US from MRMS, over Europe from the OPERA network (Huuskonen et al., 2014), and over Japan from the Japan Meteorological Agency radars. We can see that the Global Met Net model, even when trained without high quality ground radars, outperforms global and regional NWP HRRR at all lead times up to 12 hours and at all rain rates. The performance of the model trained with the regional radars as an input is the highest up to 6 hours of lead time at all precipition rates. Note here that the prediction of Global Met Net models is optimized for the GPM CORRA dataset, whereas we evaluate against radars in this figure and hence, there is some loss inherently due to the discrepancy in observations between GPM CORRA and radar datasets. At higher rates, such as 25 mm/hr, some noise is visible due to lack of sufficient observation data at those points. These results demonstrate the high skill of the model against the best available ground truth even when the ’gold standard’ of ground-based radar networks are not available during training or inference. Achieving good skill despite the absence of radar inputs is particularly critical in the Global South where radars are not widely available. This indicates the model is learning meteorologically sound patterns, rather than simply overfitting to the characteristics of a single sensor type. Figure 6 | Frequency Bias Globally and by Region for Precipitation Rates of 0.2, 2.4, and 25.0 mm/hr. When looking at the frequency bias of the Global Met Net models compared to HRES, in Figure 6, we note that there is some variation in the bias at varying lead times, rates of precipitation and regionally as well. For the 0.2 mm/hr precipitation rate, we see that Global Met Net’s bias stays close to 1 at all lead times both globally and regionally, whereas raw HRES tends to overpredict these lower thresholds more than twice. As we get to the higher rates, we can see that Global Met Net and post-processing HRES leads to an overprediction whereas HRES underpredicts globally. It should be noted that for more extreme precipitation it is better to over-predict and issue sufficient warning to end-users rather than leave them unprepared, this is commonly known as wet bias. As uncertainty of the forecast increases with lead time for higher precipitation rates, Global Met Net tends to overpredict accordingly. It is important to note here that the probabilistic inference from Global Met Net is categorized by applying probability thresholds optimizing for the CSI metric, which results in sub-optimal frequency bias scores. However, if one was interested in specifically optimizing frequency bias then it is possible to apply thresholds to optimize that instead and we noticed that it does not decrease the performance of CSI much at all. We also show results for a spatial verification metric, fractions skill scores (FSS)(Roberts and Lean, 2008) for varying sizes of pixel neighborhoods from 0.05◦to 1◦. In Figure 7, we show results of the Global Met Net models vs NWP models (HRES and HRRR) in the US using MRMS as the ground truth. Due to the narrow swaths of the GPM CORRA dataset it is not possible to apply spatial verification metrics such as FSS at much coarser resolutions therefore we provide results here against a dense ground truth like MRMS. The FSS quantifies the ability of a forecast to correctly identify precipitation patterns at different spatial scales, with higher values indicating better skill. Fractions skill score is also an important metric to look at that avoids the double penalty problem (Haiden and Lledó, 2023) Figure 7 | Fractions Skill Score (FSS) of Global Met Net vs. NWP Baselines in the US (vs. MRMS) for Various Precipitation Rates (0.2, 2.4, 7.0, and 25.0 mm/hr) across a Range of Spatial Neighborhoods (0.05° (FSS(1)) to 1° (FSS(21)). that metrics like CSI may suffer from placing NWP models at a disadvantage. Overall, Global Met Net has higher skill than both the other baselines at all of these neighborhood sizes, precipitation rates and at all lead times. As expected, looking at Figure 7, we note that the FSS generally decreases as the neighborhood size decreases (from 1° to 0.05°). This reflects the increasing difficulty of accurately predicting fine-scale precipitation features at higher resolution. Met Net is able to capture even the more chaotic, heavier precipitation events also more skillfully than NWP models at earlier lead times and meets the HRRR model by hour 12 at finer resolutions. While HRRR shows higher skill at an extremely coarse 1° neighborhood, this primarily reflects its ability to correctly place a large weather system within a very large general area. For the high-resolution scales that are most meaningful for nowcasting applications (e.g., 0.05° to 0.25°), Global Met Net consistently demonstrates superior skill in capturing the actual location and spatial structure of precipitation, making it a more valuable tool for localized warnings. 3. Global Met Net 3.1. Datasets This section outlines the multi-modal datasets used by Global Met Net, distinguishing between non- time-sensitive training targets and low-latency input features required for real-time inference. These datasets vary in spatial and temporal scales and real-time latencies, collectively enabling global coverage and enhanced prediction capabilities. Further details on each dataset are available in the supplement. 3.1.1. Training Targets An ML model is optimized by taking in a set of inputs and corresponding targets to train against. Hence, during inference when the model is operationalized, the datasets used as model training targets do not need to be available with a low latency. This gives us an opportunity to use calibrated observations in our model as training targets. Ideally, a global network of ground-based weather radars would provide the highest quality, high-resolution precipitation data for training. However, in reality, this is a challenging task for a number of reasons. Radars can be expensive to install and maintain such as over the ocean or mountains or in places lacking relevant infrastructure and trained personnel. Many times, even if radars exist they are owned by city governments or by different organisations even within a country, and their data is not easily available for use by external organisations. Furthermore, even if the raw radar data is readily available for use it can be noisy picking up false signals from flocks of birds, wind farms and sun interference. A mountainous terrain or presence of tall buildings close to the station can further lead to inaccurate data. This raw radar data requires significant processing and cleanup before it can be used as a training target or for validation. To facilitate validation and training of the model on precipitation measurements from other parts of the world and especially the tropics, we make use of NASA’s Global Precipitation Measurement (GPM) mission’s dual-frequency precipitation radar satellite. GPM provides a precipitation estimate using the CORRA algorithm, which is sparse but provides global coverage (see Figure 8 for a map of global coverage). Additionally, we use the IMERG final precipitation estimate as another training target, which is dense, but has potential inaccuracies. Table 1, summarizes the features of the training targets used by the Global Met Net model, where the target type shows that the GPM CORRA data is the main target which makes the actual predictions used in all of our evaluations and results. The other datasets serve as auxiliary training targets. Table 1 | This table summarizes the training targets and their properties. Dataset Spatial Resolution Target Patch Size Coverage Target Type GPM CORRA 0.05◦× 0.05◦ 3600 × 7200 Sparsely global Main Ground Radars 0.05◦× 0.05◦ 3600 × 7200 Dense in US, Eu- rope, Japan Auxiliary IMERG Final 0.1◦× 0.1◦ 1800 × 3600 Dense globally Auxiliary 3.1.2. Training Input Features Unlike the training targets that do not need to be available in real-time during operations, the training features should be available at least within a few hours of inference time to be relevant to the predictions. Table 2 outlines the datasets we use as gridded inputs along with their real-time latencies. These latencies are baked into the training dataset by fetching older data (corresponding to (b) 15 consecutive orbital swaths sampled by GPM CORRA, demonstrating the spatial footprint ob- served by the satellite over the course of a full day. (a) Radar coverage globally (Saltikoff et al., 2019). This figure is for illustration purposes as noted by Saltikoff et al. in Figure 1 of their paper and may not be up-to-date. Figure 8 | Global data coverage maps for the training targets. its real-time latency) than the one at the initialization time of each training example. In the table, we also mention how many historical timestamps we use for each of the inputs. Table 2 | Input Datasets. Dataset Spatial Resolution Real-time Latency # channels # historical timestamps Ground Radars 0.05◦× 0.05◦ ∼30 mins 1 6 timestamps, 15 mins apart Geostationary Satellite Mosaics 0.05◦× 0.05◦ ∼60 mins 17 3 timestamps, 30 mins apart HRES atmospheric variables 0.1◦× 0.1◦ 6 to 12 hours 63 1 last available timestamp HRES surface variables 0.1◦× 0.1◦ 6 to 12 hours 40 1 last available timestamp IMERG Early 0.1◦× 0.1◦ 5 to 6 hours 1 6 timestamps, 30 mins apart Elevation 0.05◦× 0.05◦ - 1 N / A Latitude - Longitude 0.05◦× 0.05◦ - 2 N / A The geostationary satellite mosaics is a special dataset that we create through blending and calibration of multiple satellites and we go into the details of it next. Information on the rest of the inputs can be found in Supplement A.1. 3.1.3. Geostationary Mosaics We use a total of 7 geostationary satellites as inputs to our model, that are combined into a mosaic to provide global coverage. Table 3 outlines the coverage provided by each of the satellites and the agencies that maintain them. We also use equivalent older satellites for model training, where available. We use the satpy library to do the parsing and reprojecting of the raw data into 18 mosaics at varying wavelengths from 0.47 μm to 13.3 μm. Supplement A.1.3 provides more details on each band in the mosaic. Mosaic Time Resolution and Latency We make mosaics at 30 minute intervals. This is the lowest common multiple for any dataset that contains Meteosat Second Generation satellites. Our data delivery delays are about half an hour and our processing time is under half an hour. This means our realtime mosaics lag actual real time by about an hour in total. We use level 1b calibrated data for our mosaics. This gets all the data in reflectance units for the visual bands and brightness temperature (Kelvin) for the IR bands. We also use a Gaussian center weighted blended average to blend the data together. This avoids any artifacts at the boundaries of the different satellite coverage areas. We try to blend each mosaic at the highest resolution available for any input to the given mosaic, but we cap resolutions to 1km nominal pixel size for runtime reasons. Table 3 | Geostationary satellites used for creating mosaics. Satellite Name Region Covered Agency Meteosat-11 Europe/North Africa EUMETSAT Meteosat-9 Indian Ocean EUMETSAT Meteosat-12 Europe/North Africa EUMETSAT Himawari-9 East Asia & Western Pacific Japan Meteorological Agency GOES-19 Eastern Americas & Atlantic Ocean NOAA GOES-18 Western Americas & Pacific Ocean NOAA GK-2A East Asia & Western Pacific Korea Meteorological Administration 3.2. Model Setup This section details the data processing steps, model architecture, and the approach to generating probabilistic outputs. 3.2.1. Dataset Processing The datasets were split into separate partitions for model development and evaluation. The devel- opment dataset spans from 2018 to 2023 that we further split into a dataset for training the ML model and parameter optimization (January 1, 2018, to April 30, 2022), and a smaller held-out set for fitting the probability thresholds (May 15, 2022, to May 15, 2023). Finally, the test dataset, covering the period from June 1, 2023, to May 31, 2024, was designated for final model evaluation and performance assessment. Before training, all datasets were preprocessed for consistency and quality. All the datasets, except for the NWP data, were resampled to a consistent 0.05◦×0.05◦spatial resolution. All the 0.05◦×0.05◦ datasets undergo a space-to-depth (Wang et al., 2020) operation with a block size of 2 which stacks each block of pixels to create more channels, which allows the model to analyze spatial patterns at different scales more efficiently. The NWP data, on the other hand, was resampled to a 0.1◦× 0.1◦ resolution and no space-to-depth operation is applied to it. Space-to-depth operation on higher resolution datasets was necessary firstly, to fit the data into the memory constraints and secondly, allowing concatenation of these higher resolution datasets with the lower resolution NWP data. This processing step brought all input datasets to a consistent effective grid size of 1800 × 3600 pixels before being fed into the model. We then normalize all of the input datasets to a zero mean and unit standard deviation values. The precipitation inputs from radar sources are normalized using log normalization due to the high skew of precipitation data. We then handle the missing or invalid data by replacing it with 0s. We also append each of the input datasets with timedeltas from the initialization time to inform the model. These timedeltas were effectively added as extra channels. All the time slices of the inputs are concatenated along the channel dimension, then all the inputs are also concatenated together along the channel dimension to produce the final inputs to the model. Since the global data is represented through a rectangle we add a context of 18 degrees on each left and right edges of this rectangle to avoid any artificial border artifacts. This brings the entire input data to a spatial dimension of 2160 × 3600. Instead of using a recurrent layer like an LSTM to process the time sequence of inputs, we concatenate the features from different input timesteps along the channel dimension. This creates a very wide tensor that the subsequent convolutional layers will process. This is a simpler but potentially effective way to provide temporal context. For the training data, target patches containing only missing values for any given lead time were mostly excluded and only a small percentage of such samples were kept chosen at random. We had to do this as the GPM CORRA data is quite sparse and very many target lead times only contained missing values. This ensures the model learns from valid precipitation data and prevents it from being trained on patches with no information. By filtering out these entirely empty patches, the model’s training is focused on meaningful precipitation patterns and values. The targets are discretized by 30 different precipitation rates and any precipitation rate that is beyond a reasonable range of 2 meters/hour is replaced with a value of 0. 3.2.2. Model Architecture At its core, Global Met Net, like its predecessors Met Net and Met Net-2 use an encoder-decoder structure. The encoder processes the preprocessed input tensor, learning a compressed representation of current and past weather conditions. The decoder takes this learned representation and generates forecasts at future lead times for various training targets configured as output heads. Here are some of the key architectural features: • Conditioning with Lead Time: Similar to Met Net-2, we encode the lead time as a one-hot embedding with indices from 0 to 721 representing the range between 0 and 12 hours with a 15 min interval and map them into a continuous 32-dimensional representation. Instead of feeding the lead time embedding as an input, the embedding is applied both as an additive and multiplicative factor (Perez et al., 2018) to the model inputs and to hidden representations before each activation function. This ensures that the internal computation in the network depends directly on lead time. • Initial Downsampling: The concatenated input features are first passed through another space_to_depth operation. This further reduces spatial resolution and increases channel depth, preparing the data for the main convolutional stack. • Deep Residual Network: The core of the encoder is a stack of residual blocks. Residual connections help in training very deep networks by allowing gradients to flow more easily. • Multiple Stages: The encoder has 4 stages of these residual blocks. • Number of Blocks per Stage: Each stage consists of 8 residual blocks. • Channels per Stage: The number of feature channels increases from 256 in the first stage to 384 in the subsequent stages. This allows the network to learn increasingly complex features. • Cropping: After each stage of residual blocks, a cropping operation is applied. This progressively reduces the spatial extent of the feature maps. This is done because as network depth and neuron receptive fields increase, border information becomes less relevant for predicting the central area. • Upsampling and Final Convolution: After the final residual blocks and cropping, features are upsampled by repeating values to their initial resolution before passing through a final convolutional layer. Heads that require a higher output resolution than the encoder receive further upsampling and convolutional layers. 3.2.3. Training and Optimization Features • Data Type: The training casts all input data to bfloat16 for faster training and reduced memory usage with minimal precision loss on TPUs. • Optimizer: Uses the Adam optimizer with an initial learning rate of 3e-4 with a step change mid way through training at a lower rate of 1.5e-4. • Polyak Averaging: Averages model weights over training steps, which can lead to better generalization. • Memory Optimization: Enables gradient checkpointing (rematerialization) for input prepa- ration, Res Net blocks, and heads. This saves memory by recomputing activations during the backward pass instead of storing them all, crucial for large models. • Hardware Configuration: The training job is executed on a 16x16 Dragonfish TPU pod, which effectively has 256 TPU chips and 512 TPU cores in total. 3.2.4. Probabilistic Output Heads The model uses multiple output ’heads,’ each optimized for a specific prediction target, resolution, and lead time. This allows each head to be optimized for the specific characteristics of its target variable while sharing the core of the encoder weights. In contrast to NWPs, that model uncertainty with ensemble forecasts, Global Met Net outputs a marginal probability distribution for precipitation at each location using a full categorical Softmax. Thus, each output head is discretized into bins and the model outputs the probability of precipitation for each bin for each lead time. This probabilistic approach enables a more comprehensive assessment of forecast uncertainty and improves the practical utility of the nowcasts for decision-making. Once the model has finished training on the training split of the dataset, we compute optimal probability thresholds for each discrete bin and each lead time. These thresholds are found by maximizing the CSI score on a held-out evaluation dataset. The probability thresholds, a value between 0 and 1, that results in the highest CSI on aggregate on this evaluation dataset gets fixed for future inferences and final metrics computation on the testing dataset. To assess Global Met Net’s effectiveness in real-world scenarios, this section presents case studies focusing on high-impact precipitation events. A crucial aspect of this evaluation is accounting for the significant differences in operational latency between the models. HRES forecasts have a latency of approximately six hours, whereas Global Met Net generates forecasts in under a minute. To ensure a fair and operationally relevant comparison, our analysis visualizes the earliest available forecast from each model for a given point in time, as illustrated in